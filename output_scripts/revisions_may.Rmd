---
title: "Comments on Latent Ranking"
author: "Owen G. Ward"
date: '`r Sys.Date()`'
output: 
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
    number_sections: FALSE
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  # fig.path = "paper_figure/",
  # dev = 'png',
  # fig.height = 4.5,
  # fig.width = 7,
  warning = FALSE
)


current_cohort <- 5

# don't write to this path
data_path <- "../output/"

func_dir <- "../lib/"

library(here)
library(rstan)
library(ppdiag)
Sys.setenv(LOCAL_CPPFLAGS = "-march=corei7 -mtune=corei7")
options(mc.cores = parallel::detectCores())
library(tidyverse)
library(R.utils)
library(RColorBrewer)
library(fields)
library(bayesplot)
library(viridis)
library(here)
library(compete)
library(colorspace)
source(paste(func_dir, "naiveRankHierarchy.R", sep = ""))
source(paste(func_dir, "expertRankHierarchy.R", sep = ""))
source(paste(func_dir, "cleanData.R", sep = ""))
source(paste(func_dir, "prepareDataStan.R", sep = ""))
source(paste(func_dir, "inferLatentMmhp.R", sep = ""))
source(paste(func_dir, "plotUtil.R", sep = ""))
source(paste(func_dir, "mmhp.R", sep = ""))
source(paste(func_dir, "uniHawkes.R", sep = ""))
source(paste(func_dir, "simulatePrediction.R", sep = ""))
source(paste(func_dir, "myGlicko.R", sep = ""))
source(paste(func_dir, "matrixPlotParameter.R", sep = ""))
source(paste(func_dir, "residualStructureScore.R", sep = ""))
source(paste(func_dir, "drawIntensity.R", sep = ""))
source("https://gist.githubusercontent.com/jalapic/6ca3ece44bdcdc522bb735f183aa0ca0/raw/1a07f469eff08117121b6cbebcd22fb7569e3ee8/compete_extra.R")

cohort_names <- paste("cohort",c(9,10,12,15,16,17,18,37,38,45),sep='')
cohort_short_names <- paste("C",c(9,10,12,15,16,17,18,37,38,45),sep='')
cut_off <- 3
mice_number <- 12

full_data <- readRDS("../data/mice.RData")

fit_cohorts <- c(1:10)
naive_rank_10 <- list()
expert_rank_10 <- list()
out <- captureOutput(for(curr_cohort in fit_cohorts){
  naive_rank_10[[curr_cohort]] <-
    naiveRankHierarchy(full_data[[cohort_names[curr_cohort]]])
  expert_rank_10[[curr_cohort]] <-
    expertRankHierarchy(full_data[[cohort_names[curr_cohort]]])
})

theme_set(theme_minimal())

```

## Run some longer/larger simulations

We can replace the simulation example with 5 nodes to one with
20 nodes.

```{r simulate_20_nodes}
num_nodes <- 20
cut_off <- 3
obs_time <- 200

model1_fn <- list(alpha.fun = function(x, y, eta1, eta2, eta3) {
  return(eta1 * x * y * exp(-eta2 * abs(x - y)) / (1 + exp(-eta3 * (x - y))))
})

model3_fn <- list(
  alpha.fun = function(x, y, eta1, eta2) {
    return(eta1 * x * y * exp(-eta2 * abs(x - y)))
  },
  q1.fun = function(x, y, eta3) {
    return(exp(-eta3 * x))
  },
  q0.fun = function(x, y, eta3) {
    return(exp(-eta3 * y))
  }
)


#### Save the simulation parameters ####

object_fn <- list(
  alpha.fun = function(x, y, eta1, eta2) {
    return(eta1 * x * y * exp(-eta2 * abs(x - y)))
  },
  q1.fun = function(x, y, eta3) {
    return(exp(-eta3 * x))
  },
  q0.fun = function(x, y, eta3) {
    return(exp(-eta3 * y))
  }
)

object_par <- list(
  sim_lambda_1 = 0.2,
  sim_eta_1 = 1.5, # this has to be < beta
  gamma_var = runif(n = num_nodes, min = 0.01, max = 0.05),
  zeta_var = runif(n = num_nodes, min = 0.01, max = 0.05),
  sim_eta_2 = 0.6,
  sim_eta_3 = 3,
  sim_beta = 2,
  f_vec_1 = seq(
    from = 0.05, to = 0.95,
    length.out = num_nodes
  )
)

object_matrix <- list(
  lambda0_matrix = outer(
    object_par$gamma_var,
    object_par$zeta_var, "+"
  ),
  lambda1_matrix = matrix(object_par$sim_lambda_1,
    nrow = length(object_par$f_vec_1),
    ncol = length(object_par$f_vec_1)
  ),
  alpha_matrix = formMatrix(
    function(x, y) {
      object_fn$alpha.fun(
        x, y, object_par$sim_eta_1,
        object_par$sim_eta_2
      )
    },
    object_par$f_vec_1
  ),
  beta_matrix = matrix(object_par$sim_beta,
    nrow = length(object_par$f_vec_1),
    ncol = length(object_par$f_vec_1)
  ),
  q1_matrix = formMatrix(
    function(x, y) {
      object_fn$q1.fun(
        x, y,
        object_par$sim_eta_3
      )
    },
    object_par$f_vec_1
  ),
  q2_matrix = formMatrix(
    function(x, y) {
      object_fn$q0.fun(
        x, y,
        object_par$sim_eta_3
      )
    },
    object_par$f_vec_1
  )
)


## Simulate
sim_model3_data <- list()
N_array <- array(0, c(1, num_nodes, num_nodes))
# for(i in c(1:n_sim)){
sim_model3_data <- simulateLatentMMHP(
  lambda0_matrix =
    object_matrix$lambda0_matrix,
  lambda1_matrix =
    object_matrix$lambda1_matrix,
  alpha_matrix = object_matrix$alpha_matrix,
  beta_matrix = object_matrix$beta_matrix,
  q1_matrix = object_matrix$q1_matrix,
  q2_matrix = object_matrix$q2_matrix,
  horizon = obs_time
)
clean_sim_data <- cleanSimulationData(
  raw_data = sim_model3_data,
  cut_off = cut_off,
  N = length(object_par$f_vec_1)
)
N_array <- clean_sim_data$N_count
```


We wish to confirm that this simulation study actually results
in sensible, such as whether the I&SI is consistent with
the true latent rankings.


We can also plot the MMHP fit for a single pair using `ppdiag`.

```{r plot_pair}
start <- 20
end <- 10

poss_start <- which(clean_sim_data$I_fit == start)
poss_end <- which(clean_sim_data$J_fit == end)

pair_id <- intersect(poss_start, poss_end)

events <- clean_sim_data$event_matrix[pair_id, ]
events <- events[events > 0]

q1 <- object_matrix$q1_matrix[start, end]
q2 <- object_matrix$q2_matrix[start, end]

obj <- pp_mmhp(
  lambda0 = object_matrix$lambda0_matrix[start, end],
  lambda1 = object_matrix$lambda1_matrix[start, end],
  alpha = object_matrix$alpha_matrix[start, end],
  beta = object_matrix$beta_matrix[start, end],
  Q = matrix(c(-q1, q1, q2, -q2), nrow = 2, ncol = 2, byrow = TRUE)
)

pp_residual(obj, events, end = obs_time)

# can't plot the mmhp unless you infer the latent process
### can use viterbi and such for now

obj$q1 <- q1
obj$q2 <- q2

viterbi_result <- myViterbi(
  events = events,
  param = obj,
  termination = obs_time
)

latent_inter <- interpolateLatentTrajectory(obj,
  events,
  viterbi_result$zt_v,
  initial.state =
    viterbi_result$initial_state,
  termination.time = obs_time,
  termination.state =
    viterbi_result$termination_state
)


event_state <- ppdiag:::mmhp_event_state(params = obj, events = events)

latent_state <- ppdiag:::interpolate_mmhp_latent(
  params = obj, events,
  zt = event_state$zt
)

mmhp_latent <- list()
mmhp_latent$start <- 0
mmhp_latent$end <- obs_time
mmhp_latent$x <- c(0, latent_state$x.hat, obs_time)
mmhp_latent$z <- c(viterbi_result$initial_state, latent_state$z.hat)
mmhp_latent$events <- c(0, events)
mmhp_latent$zt <- c(1, event_state$zt)
ppdiag::drawUniMMHPIntensity(obj, mmhp_latent)

# this plot is not correct for later Hawkes states...
## don't think the bug is with ppdiag
```

```{r ranking_sim_data}
### i&si method
count_data_dc <- get_wl_matrix(df = cbind(
  clean_sim_data$start,
  clean_sim_data$end
))
isi_dc.out <- compete::isi98(m = count_data_dc, random = TRUE)
as.numeric(isi_dc.out$best_order) # from highest to lowest

### agg rank method
agg_rank_data <- clean_sim_data$N_count
agg_rank_model <- stan_model(here("lib", "latent_rank_agg_sim.stan"))

agg_rank_fit <- rstan::sampling(agg_rank_model,
  data = list(
    n = num_nodes,
    n_matrix = agg_rank_data
  ),
  iter = 1000,
  chains = 4
)
agg_sims <- rstan::extract(agg_rank_fit)

agg_rank <- order(apply(agg_sims$x, 2, mean))
rev(agg_rank) # from highest to lowest

### then glicko
glicko_data <- tibble(
  start = clean_sim_data$start,
  end = clean_sim_data$end
)

glicko_data <- glicko_data %>%
  mutate(id = row_number(), score = 1) %>%
  select(id, start, end, score)

library(PlayerRatings)
gl_train <- my_glicko(glicko_data, history = TRUE, cval = 2)

gl_train

gl_ranks <- order(gl_train$ratings$Rating)
gl_ranks # highest to lowest
```


So there is some structure in this data here that is perhaps 
best picked up by the I&SI method.


Similarly, we can confirm we get sensible fits by fitting the individual
MMHP model to each pair and showing the residuals. This
is consistent with what we see for real data, where the
residual matrices show overall small positive values, indicating
underestimation when we fit individual models.

```{r residuals-immhp-sim}
pr_matrix <- readRDS(here("output", "revisions", "pr_matrix_immhp.RDS"))
rr_matrix <- readRDS(here("output", "revisions", "rr_matrix_immhp.RDS"))
# image(pr_matrix)

matrix_lst_plot <- list()
matrix_lst_plot[[1]] <- rr_matrix
matrix_lst_plot[[2]] <- pr_matrix


myMultiMatrixPlot(
  X = matrix_lst_plot,
  no_matrix = 2,
  n_row = 1,
  xLabels = 1:20,
  yLabels = 20:1,
  min = -30,
  max = 30,
  axis_cex = 2,
  title_cex = 1.8,
  colorPalette = "RdBu",
  if.emp = FALSE,
  # legend.mar=c(0.5,.5,0.5,0.5),
  title_lst = list("Raw", "Pearson"),
  # title_lst = list("I-MMHP"),
  col_axis = c(-30, -15, 0, 15, 30),
  fake_matrix = TRUE,
  matrix.mar = c(2.5, 2.5, 2.5, 1)
)
```



## Explaining the g function

```{r plot_g}
alpha.fun <- function(x, y, eta1, eta2) {
  return(eta1 * x * y * exp(-eta2 * abs(x - y)))
}

f_vec <- c(0.1, 0.2, 0.4, 0.8, 0.9)

eta1 <- 6.6
eta2 <- 0.37


crossing(send = f_vec, rec = f_vec) %>%
  filter(send != rec) %>%
  mutate(alpha = alpha.fun(send, rec, eta1, eta2))
```


## Larger Simulation Study

```{r load_in_large_sim}
load(here("output", "revisions", "sim_model3_immhp_.RData"))
load(here("output", "revisions", "sim_model3_fit_cmmhp_.RData"))

post_rank <- post_draws %>% 
  select(starts_with("f")) %>% 
  ## rename the f cols first
  rename_with(~gsub("[", "_", .x, fixed = TRUE)) %>% 
  rename_with(~gsub("]", "", .x, fixed = TRUE)) %>% 
  pivot_longer(everything(),
               names_to = "node",
               values_to = "rank") 
  # group_by(node) %>% 
  # summarise(ave_rank = mean(rank), sd_rank = sd(rank)) %>% 

## order nodes
# post_rank$node <- as.factor(post_rank$node)
true_rank <- tibble(names = paste0("f_", 1:20),
                    f_vec_1 = seq(from = 0.05,
                                  to = 0.95,
                                  length.out = 20))

post_rank$node <- factor(post_rank$node, levels = paste0("f_", 1:20))

post_mean <- post_rank %>%
  group_by(node) %>% 
  summarise(ave_rank = mean(rank))

post_rank %>% 
  ggplot(aes(node, rank)) + 
  geom_boxplot() +
  geom_point(data = true_rank,
             mapping = aes(names, f_vec_1, shape = 16),
             colour = "red") +
  geom_point(data = post_mean,
             mapping = aes(node, ave_rank, shape = 16),
             colour = "blue") +
  scale_shape_identity() +
  labs(title = "Inferred Latent Ranking with Truth",
       x = "Node", y = "Latent Ranking",
       colour = "Summary")
## blue is posterior mean, red is true value
## can add legend to fix this
```

What else should we infer with a larger simulation example? How do we visualise 
the results in this case?

## Stability of Rankings over Time

```{r load_cohort_rankings}
for(cohort_id in 1:10){
  start_rank <- readRDS(file = paste(data_path,
                                 "/revisions/rank_stab/", "cohort_",
                                 cohort_id, "start.RDS",
                                 sep = ""))

  end_rank <- readRDS(file = paste(data_path,
                                   "/revisions/rank_stab/", "cohort_",
                                   cohort_id, "end.RDS",
                                   sep = ""))
  ### plot both of these
  init_ranks <- start_rank %>%
    select(starts_with("f")) %>%
    rename_with(~gsub("[", "_", .x, fixed = TRUE)) %>%
    rename_with(~gsub("]", "", .x, fixed = TRUE)) %>%
    pivot_longer(everything(),
                 names_to = "node",
                 values_to = "rank")
  
  final_ranks <- end_rank %>%
    select(starts_with("f")) %>%
    rename_with(~gsub("[", "_", .x, fixed = TRUE)) %>%
    rename_with(~gsub("]", "", .x, fixed = TRUE)) %>%
    pivot_longer(everything(),
                 names_to = "node",
                 values_to = "rank")
  
  init_ranks$node <- factor(init_ranks$node, levels = paste0("f_", 1:12))
  final_ranks$node <- factor(final_ranks$node, levels = paste0("f_", 1:12))
  
  init_ranks$when <- "first14"
  final_ranks$when <- "last14"
  
  init_ranks %>% 
    ggplot(aes(node, rank)) + 
    geom_boxplot() +
    labs(title = "Ranking from first 14 Days")
  
  final_ranks %>% 
    ggplot(aes(node, rank)) + 
    geom_boxplot() +
    labs(title = "Ranking from final 14 Days")
  
  all_ranks <- bind_rows(init_ranks, final_ranks) 
  
  coh_plot <- all_ranks %>% 
    ggplot(aes(node, rank, fill = when)) +
    geom_boxplot() +
    labs(x = "Mouse",
         y = "Latent Rank", 
         fill = "Time Period",
         title = "Agreement between initial and later ranking",
         subtitle = "One Cohort")
  print(coh_plot)
}

```


## Community Structure Plot

```{r construct_plot}
iAndSI <- function(M) {
  n <- ncol(M)
  result <- rep(0, 2)
  k <- (M - t(M)) / 2
  k[upper.tri(k)] <- 0
  result[1] <- 0
  a <- length(which(k > 0))
  y <- which(k > 0) %% n
  x <- (which(k > 0) - 1) %/% n + 1
  y[y == 0] <- y[y == 0] + n
  if (a > 0) {
    result[1] <- a
    result[2] <- sum(y - x)
  }
  return(result)
}



state_types <- c("total", "utility", "social")
metric_types <- c("dc", "ttri", "i")
state_separation_result <- data.frame(array(0,
                                            c(10 * 
                                                length(state_types) *
                                                length(metric_types),
                                              4)))
colnames(state_separation_result) <- c("cohort", "state", "metric", "value")

total_event_array_lst <- list()
active_event_array_lst <- list()
for (current_cohort in c(2:10)) {
  print(current_cohort)
  load(paste(data_path, 
             cohort_names[current_cohort],
    "/cmmhp_est_zt_",
    cohort_names[current_cohort],
    ".RData",
    sep = ""
  ))
  clean_data <- cleanData(full_data[[cohort_names[current_cohort]]])
  return_df <- cleanObservationPeriod(
    current_cohort, 
    raw_df =  full_data[[cohort_names[current_cohort]]],
    clean_data)
  unique_pairs_df <- return_df %>%
    group_by(initiator, recipient) %>%
    dplyr::summarize(
      count = n(),
      observe = list(observe.id),
      observe.length = list(observe.time),
      no.events = list(no.events)
    )
  unique_observe_win <- unique(return_df[, c("observe.id", "observe.time")])

  expert_rank <- expert_rank_10[[current_cohort]]

  # -------- Load the saved stan result, 
  # -------- plot the inferred parameters and save
  total_event_array_lst[[current_cohort]] <- 
    array(0, dim = c(mice_number, mice_number, max(return_df$observe.id)))
  active_event_array_lst[[current_cohort]] <-
    array(0, dim = c(mice_number, mice_number, max(return_df$observe.id)))

  for (i in 1:mice_number) {
    for (j in 1:mice_number) {
      pair <- which(unique_pairs_df$initiator == i & 
                      unique_pairs_df$recipient == j)
      if (length(pair) > 0) {
        current_window_vec <- unique_pairs_df$observe[[pair]]
        for (cur_win in current_window_vec) {
          row_indicator <- (return_df$initiator == i) & 
            (return_df$recipient == j) &
            (return_df$observe.id == cur_win)
          total_event_array_lst[[current_cohort]][i, j, cur_win] <-
            length(return_df[row_indicator, "event.times"][[1]])
          active_event_array_lst[[current_cohort]][i, j, cur_win] <- 
            sum(apply(2 - state_array_list[[pair]][[cur_win]], 1, mean) > 0.5)
        }
      }
    }
  }

  start_win <- floor(max(return_df$observe.id) / 2)
  end_win <- max(return_df$observe.id)
  matrix1 <- apply(
    total_event_array_lst[[current_cohort]][, , start_win:end_win],
    c(1, 2),
    sum
    )[expert_rank, expert_rank]
  matrix2 <- apply(
    active_event_array_lst[[current_cohort]][, , start_win:end_win],
    c(1, 2),
    sum
    )[expert_rank, expert_rank]
  matrix3 <- apply(
    total_event_array_lst[[current_cohort]][, , start_win:end_win] -
      active_event_array_lst[[current_cohort]][, , start_win:end_win],
    c(1, 2),
    sum
    )[expert_rank, expert_rank]

  # ------ compute metrics ------
  state_separation_result$cohort[
    ((current_cohort - 1) * 
      length(metric_types) *
      length(state_types) + 1):(current_cohort * length(metric_types) *
                                  length(state_types))] <-
    cohort_names[current_cohort]
  state_separation_result$metric[
    ((current_cohort - 1) *
       length(metric_types) *
       length(state_types) + 1):(current_cohort * length(metric_types) *
                                   length(state_types))] <- 
    rep(c("dc", "ttri", "i"), length(state_types))

  state_separation_result$state[
    ((current_cohort - 1) *
       length(metric_types) *
       length(state_types) + 1):(current_cohort * length(metric_types) *
                                   length(state_types) -
                                   length(metric_types) * 2)] <- "total"
  
  ## bug below here need to find iAndSI
  state_separation_result$value[
    ((current_cohort - 1) *
       length(metric_types) *
       length(state_types) + 1):(current_cohort * length(metric_types) *
                                   length(state_types) - 
                                   length(metric_types) * 2)] <- 
    c(dci(matrix1), ttri(matrix1)[[2]], iAndSI(matrix1)[1])

  state_separation_result$state[
    ((current_cohort - 1) *
       length(metric_types) *
       length(state_types) + 
       length(metric_types) + 1):(current_cohort * 
                                    length(metric_types) *
                                    length(state_types) -
                                    length(metric_types))] <-
    "utility"
  state_separation_result$value[
    ((current_cohort - 1) *
       length(metric_types) * 
       length(state_types) + 
       length(metric_types) + 1):(current_cohort * length(metric_types)
                                  * length(state_types)
                                  - length(metric_types))] <-
    c(dci(matrix2), ttri(matrix2)[[2]], iAndSI(matrix2)[1])

  state_separation_result$state[(current_cohort * length(metric_types) *
                                   length(state_types) - 
                                   length(metric_types) + 1):(
                                     current_cohort * length(metric_types) *
                                       length(state_types))] <- "social"
  state_separation_result$value[(current_cohort * length(metric_types) *
                                   length(state_types) -
                                   length(metric_types) + 1):(
                                     current_cohort * length(metric_types) *
                                       length(state_types))] <- 
    c(dci(matrix3), ttri(matrix3)[[2]], iAndSI(matrix3)[1])
}

save(state_types, metric_types, state_separation_result,
  total_event_array_lst, active_event_array_lst,
  file = "../output/state_separation_plot.RData"
)

```


```{r recreate_jing_figure}
load("../output/state_separation_plot.RData")
for (current_cohort in c(2)) {
  total_event_array <- total_event_array_lst[[current_cohort]]
  active_event_array <- active_event_array_lst[[current_cohort]]
  clean_data <- cleanData(full_data[[cohort_names[current_cohort]]])
  return_df <- cleanObservationPeriod(current_cohort, 
                                      full_data[[cohort_names[current_cohort]]],
                                      clean_data)

  start_win <- floor(max(return_df$observe.id) / 3) * (0:2) + 1
  end_win <- floor(max(return_df$observe.id) / 3) * (1:3)
  matrix1 <- apply(
    total_event_array[, , start_win[1]:end_win[1]] -
      active_event_array[, , start_win[1]:end_win[1]],
    c(1, 2), sum
  )
  matrix2 <- apply(
    total_event_array[, , start_win[2]:end_win[2]] -
      active_event_array[, , start_win[2]:end_win[2]],
    c(1, 2), sum
  )
  matrix3 <- apply(
    total_event_array[, , start_win[3]:end_win[3]] -
      active_event_array[, , start_win[3]:end_win[3]],
    c(1, 2), sum
  )
  ### work to here
  g_community1 <- graph_from_adjacency_matrix(matrix1, mode = "undirected")
  lec1 <- cluster_leading_eigen(g_community1)

  g_community2 <- graph_from_adjacency_matrix(matrix2, mode = "undirected")
  lec2 <- cluster_leading_eigen(g_community2)

  g_community3 <- graph_from_adjacency_matrix(matrix3, mode = "undirected")
  lec3 <- cluster_leading_eigen(g_community3)

  ### Make plot for t=1
  png(paste(plot_path, "real_clustering_1.png", sep = ""), 
      height = 600,
      width = 600)
  myCircularPlot(
    cur.matrix = matrix1,
    cur.order = c(1, 4, 10, 5, 11, 6, 7, 2, 8, 12, 9, 3),
    cur.color = c(
      colorRampPalette(brewer.pal(
        name = "YlOrBr",
        n =
          8
      ))(14)[c(
        13,
        9,
        5
      )],
      colorRampPalette(brewer.pal(
        name = "PuRd",
        n =
          8
      ))(15)[c(
        4,
        6,
        8,
        10,
        12,
        14
      )],
      colorRampPalette(brewer.pal(
        name = "Blues",
        n =
          8
      ))(10)[c(
        5,
        7,
        9
      )]
    ),
    cur.gap = c(rep(5, 2), 30, rep(5, 5), 30, rep(5, 2), 30)
  )
  dev.off()

  ### Make plot for t=2
  png(paste(plot_path, "real_clustering_2.png", sep = ""),
   height = 600,
   width = 600
 )
 myCircularPlot(
   cur.matrix = matrix2,
   cur.order = c(1, 7, 8, 2, 3, 4, 5, 9, 10, 6, 11, 12),
   cur.color = c(
     colorRampPalette(brewer.pal(
       name = "YlOrBr",
       n = 8))(14)[c(13, 11, 9, 7, 5, 3)],
     colorRampPalette(brewer.pal(
       name = "Blues",
       n = 8))(15)[c(4, 6, 8, 10, 12, 14)]
   ),
   cur.gap = c(rep(5, 5), 30, rep(5, 5), 30)
 )
 dev.off()

  ### Make plot for t=3
  png(paste(plot_path, "real_clustering_3.png", sep = ""),
      height = 600,
      width = 600)
  myCircularPlot(
    cur.matrix = matrix3[-3, -3],
    cur.order = c(1, 10, 5, 2, 3, 6, 7, 8, 4, 11, 9),
    cur.color = c(
      colorRampPalette(
        brewer.pal(name = "YlOrBr",
                   n = 8))(14)[c(13, 9, 5, 3)],
      colorRampPalette(brewer.pal(
        name = "Blues",
        n = 8))(16)[c(7, 9, 11, 13, 15)],
      colorRampPalette(brewer.pal(
        name = "PuRd",
        n = 8))(15)[c(8, 12)]
    ),
    cur.gap = c(rep(5, 3), 30, rep(5, 4), 30, rep(5, 1), 30),
    cur.ID = c(1:12)[-3]
  )
  dev.off()
}
```
