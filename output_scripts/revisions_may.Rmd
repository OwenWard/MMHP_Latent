---
title: "Comments on Latent Ranking"
author: "Owen G. Ward"
date: '`r Sys.Date()`'
output: 
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
    number_sections: FALSE
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  # fig.path = "paper_figure/",
  # dev = 'png',
  # fig.height = 4.5,
  # fig.width = 7,
  warning = FALSE
)


current_cohort <- 5

# don't write to this path
data_path <- "../output/"

func_dir <- "../lib/"

library(here)
library(rstan)
library(ppdiag)
Sys.setenv(LOCAL_CPPFLAGS = "-march=corei7 -mtune=corei7")
options(mc.cores = parallel::detectCores())
library(tidyverse)
library(R.utils)
library(RColorBrewer)
library(fields)
library(bayesplot)
library(viridis)
library(here)
library(igraph)
library(compete)
library(circlize)
library(colorspace)
source(paste(func_dir, "naiveRankHierarchy.R", sep = ""))
source(paste(func_dir, "expertRankHierarchy.R", sep = ""))
source(paste(func_dir, "cleanData.R", sep = ""))
source(paste(func_dir, "prepareDataStan.R", sep = ""))
source(paste(func_dir, "inferLatentMmhp.R", sep = ""))
source(paste(func_dir, "plotUtil.R", sep = ""))
source(paste(func_dir, "mmhp.R", sep = ""))
source(paste(func_dir, "uniHawkes.R", sep = ""))
source(paste(func_dir, "simulatePrediction.R", sep = ""))
source(paste(func_dir, "myGlicko.R", sep = ""))
source(paste(func_dir, "matrixPlotParameter.R", sep = ""))
source(paste(func_dir, "residualStructureScore.R", sep = ""))
source(paste(func_dir, "drawIntensity.R", sep = ""))
source(paste(func_dir, "circularPlot.R", sep = ""))
source("https://gist.githubusercontent.com/jalapic/6ca3ece44bdcdc522bb735f183aa0ca0/raw/1a07f469eff08117121b6cbebcd22fb7569e3ee8/compete_extra.R")

cohort_names <- paste("cohort",c(9,10,12,15,16,17,18,37,38,45),sep='')
cohort_short_names <- paste("C",c(9,10,12,15,16,17,18,37,38,45),sep='')
cut_off <- 3
mice_number <- 12

full_data <- readRDS("../data/mice.RData")

fit_cohorts <- c(1:10)
naive_rank_10 <- list()
expert_rank_10 <- list()
out <- captureOutput(for(curr_cohort in fit_cohorts){
  naive_rank_10[[curr_cohort]] <-
    naiveRankHierarchy(full_data[[cohort_names[curr_cohort]]])
  expert_rank_10[[curr_cohort]] <-
    expertRankHierarchy(full_data[[cohort_names[curr_cohort]]])
})

theme_set(theme_minimal())

col_df <- tibble(method = c("I&SI",
                            "AggRank",
                            "DSNL",
                            "Glicko",
                            "I-MMHP",
                            "C-HP",
                            "C-DCHP",
                            "True",
                            "C-MMHP"),
            cols = viridis(9))

model1_fn <- list(alpha.fun = function(x, y, eta1, eta2, eta3) {
  return(eta1 * x * y * exp(-eta2 * abs(x - y)) / (1 + exp(-eta3 * (x - y))))
})

model3_fn <- list(
  alpha.fun = function(x, y, eta1, eta2) {
    return(eta1 * x * y * exp(-eta2 * abs(x - y)))
  },
  q1.fun = function(x, y, eta3) {
    return(exp(-eta3 * x))
  },
  q0.fun = function(x, y, eta3) {
    return(exp(-eta3 * y))
  }
)

```

## Run some longer/larger simulations

We can replace the simulation example with 5 nodes to one with
20 nodes.

```{r simulate_20_nodes}
num_nodes <- 20
cut_off <- 3
obs_time <- 200



#### Save the simulation parameters ####

object_fn <- list(
  alpha.fun = function(x, y, eta1, eta2) {
    return(eta1 * x * y * exp(-eta2 * abs(x - y)))
  },
  q1.fun = function(x, y, eta3) {
    return(exp(-eta3 * x))
  },
  q0.fun = function(x, y, eta3) {
    return(exp(-eta3 * y))
  }
)

object_par <- list(
  sim_lambda_1 = 0.2,
  sim_eta_1 = 1.5, # this has to be < beta
  gamma_var = runif(n = num_nodes, min = 0.01, max = 0.05),
  zeta_var = runif(n = num_nodes, min = 0.01, max = 0.05),
  sim_eta_2 = 0.6,
  sim_eta_3 = 3,
  sim_beta = 2,
  f_vec_1 = seq(
    from = 0.05, to = 0.95,
    length.out = num_nodes
  )
)

object_matrix <- list(
  lambda0_matrix = outer(
    object_par$gamma_var,
    object_par$zeta_var, "+"
  ),
  lambda1_matrix = matrix(object_par$sim_lambda_1,
    nrow = length(object_par$f_vec_1),
    ncol = length(object_par$f_vec_1)
  ),
  alpha_matrix = formMatrix(
    function(x, y) {
      object_fn$alpha.fun(
        x, y, object_par$sim_eta_1,
        object_par$sim_eta_2
      )
    },
    object_par$f_vec_1
  ),
  beta_matrix = matrix(object_par$sim_beta,
    nrow = length(object_par$f_vec_1),
    ncol = length(object_par$f_vec_1)
  ),
  q1_matrix = formMatrix(
    function(x, y) {
      object_fn$q1.fun(
        x, y,
        object_par$sim_eta_3
      )
    },
    object_par$f_vec_1
  ),
  q2_matrix = formMatrix(
    function(x, y) {
      object_fn$q0.fun(
        x, y,
        object_par$sim_eta_3
      )
    },
    object_par$f_vec_1
  )
)


## Simulate
sim_model3_data <- list()
N_array <- array(0, c(1, num_nodes, num_nodes))
# for(i in c(1:n_sim)){
sim_model3_data <- simulateLatentMMHP(
  lambda0_matrix =
    object_matrix$lambda0_matrix,
  lambda1_matrix =
    object_matrix$lambda1_matrix,
  alpha_matrix = object_matrix$alpha_matrix,
  beta_matrix = object_matrix$beta_matrix,
  q1_matrix = object_matrix$q1_matrix,
  q2_matrix = object_matrix$q2_matrix,
  horizon = obs_time
)
clean_sim_data <- cleanSimulationData(
  raw_data = sim_model3_data,
  cut_off = cut_off,
  N = length(object_par$f_vec_1)
)
N_array <- clean_sim_data$N_count
```


We wish to confirm that this simulation study actually results
in sensible, such as whether the I&SI is consistent with
the true latent rankings.


We can also plot the MMHP fit for a single pair using `ppdiag`.

```{r plot_pair}
start <- 20
end <- 10

poss_start <- which(clean_sim_data$I_fit == start)
poss_end <- which(clean_sim_data$J_fit == end)

pair_id <- intersect(poss_start, poss_end)

events <- clean_sim_data$event_matrix[pair_id, ]
events <- events[events > 0]

q1 <- object_matrix$q1_matrix[start, end]
q2 <- object_matrix$q2_matrix[start, end]

obj <- pp_mmhp(
  lambda0 = object_matrix$lambda0_matrix[start, end],
  lambda1 = object_matrix$lambda1_matrix[start, end],
  alpha = object_matrix$alpha_matrix[start, end],
  beta = object_matrix$beta_matrix[start, end],
  Q = matrix(c(-q1, q1, q2, -q2), nrow = 2, ncol = 2, byrow = TRUE)
)

pp_residual(obj, events, end = obs_time)

# can't plot the mmhp unless you infer the latent process
### can use viterbi and such for now

obj$q1 <- q1
obj$q2 <- q2

viterbi_result <- myViterbi(
  events = events,
  param = obj,
  termination = obs_time
)

latent_inter <- interpolateLatentTrajectory(obj,
  events,
  viterbi_result$zt_v,
  initial.state =
    viterbi_result$initial_state,
  termination.time = obs_time,
  termination.state =
    viterbi_result$termination_state
)


event_state <- ppdiag:::mmhp_event_state(params = obj, events = events)

latent_state <- ppdiag:::interpolate_mmhp_latent(
  params = obj, events,
  zt = event_state$zt
)

mmhp_latent <- list()
mmhp_latent$start <- 0
mmhp_latent$end <- obs_time
mmhp_latent$x <- c(0, latent_state$x.hat, obs_time)
mmhp_latent$z <- c(viterbi_result$initial_state, latent_state$z.hat)
mmhp_latent$events <- c(0, events)
mmhp_latent$zt <- c(1, event_state$zt)
ppdiag::drawUniMMHPIntensity(obj, mmhp_latent)

# this plot is not correct for later Hawkes states...
## don't think the bug is with ppdiag
```

```{r ranking_sim_data, include=FALSE, eval=FALSE}
### i&si method
count_data_dc <- get_wl_matrix(df = cbind(
  clean_sim_data$start,
  clean_sim_data$end
))
isi_dc.out <- compete::isi98(m = count_data_dc, random = TRUE)
as.numeric(isi_dc.out$best_order) # from highest to lowest

### agg rank method
agg_rank_data <- clean_sim_data$N_count
agg_rank_model <- stan_model(here("lib", "latent_rank_agg_sim.stan"))

agg_rank_fit <- rstan::sampling(agg_rank_model,
  data = list(
    n = num_nodes,
    n_matrix = agg_rank_data
  ),
  iter = 1000,
  chains = 4
)
agg_sims <- rstan::extract(agg_rank_fit)

agg_rank <- order(apply(agg_sims$x, 2, mean))
rev(agg_rank) # from highest to lowest

### then glicko
glicko_data <- tibble(
  start = clean_sim_data$start,
  end = clean_sim_data$end
)

glicko_data <- glicko_data %>%
  mutate(id = row_number(), score = 1) %>%
  select(id, start, end, score)

library(PlayerRatings)
gl_train <- my_glicko(glicko_data, history = TRUE, cval = 2)

gl_train

gl_ranks <- order(gl_train$ratings$Rating)
gl_ranks # highest to lowest
```


So there is some structure in this data here that is perhaps 
best picked up by the I&SI method.


Similarly, we can confirm we get sensible fits by fitting the individual
MMHP model to each pair and showing the residuals. This
is consistent with what we see for real data, where the
residual matrices show overall small positive values, indicating
underestimation when we fit individual models.

```{r residuals-immhp-sim}
pr_matrix <- readRDS(here("output", "revisions", "pr_matrix_immhp.RDS"))
rr_matrix <- readRDS(here("output", "revisions", "rr_matrix_immhp.RDS"))
# image(pr_matrix)

matrix_lst_plot <- list()
matrix_lst_plot[[1]] <- rr_matrix
matrix_lst_plot[[2]] <- pr_matrix


myMultiMatrixPlot(
  X = matrix_lst_plot,
  no_matrix = 2,
  n_row = 1,
  xLabels = 1:20,
  yLabels = 20:1,
  min = -30,
  max = 30,
  axis_cex = 2,
  title_cex = 1.8,
  colorPalette = "RdBu",
  if.emp = FALSE,
  # legend.mar=c(0.5,.5,0.5,0.5),
  title_lst = list("Raw", "Pearson"),
  # title_lst = list("I-MMHP"),
  col_axis = c(-30, -15, 0, 15, 30),
  fake_matrix = TRUE,
  matrix.mar = c(2.5, 2.5, 2.5, 1)
)
```



## Explaining the g function

```{r plot_g}
alpha.fun <- function(x, y, eta1, eta2) {
  return(eta1 * x * y * exp(-eta2 * abs(x - y)))
}

f_vec <- c(0.1, 0.2, 0.4, 0.8, 0.9)

eta1 <- 6.6
eta2 <- 0.37


tidyr::crossing(send = f_vec, rec = f_vec) %>%
  filter(send != rec) %>%
  mutate(alpha = alpha.fun(send, rec, eta1, eta2))
```


## Larger Simulation Study

```{r load_in_large_sim}
load(here("output", "revisions", "sim_model3_immhp_.RData"))
load(here("output", "revisions", "sim_model3_fit_cmmhp_.RData"))

post_rank <- post_draws %>% 
  select(starts_with("f")) %>% 
  ## rename the f cols first
  rename_with(~gsub("f[", "", .x, fixed = TRUE)) %>% 
  rename_with(~gsub("]", "", .x, fixed = TRUE)) %>% 
  pivot_longer(everything(),
               names_to = "node",
               values_to = "rank") 
  # group_by(node) %>% 
  # summarise(ave_rank = mean(rank), sd_rank = sd(rank)) %>% 

## order nodes
# post_rank$node <- as.factor(post_rank$node)
true_rank <- tibble(names = paste0("", 1:20),
                    f_vec = seq(from = 0.05,
                                  to = 0.95,
                                  length.out = 20),
                    value = "True Value")

post_rank$node <- factor(post_rank$node, levels = paste0("", 1:20))

post_mean <- post_rank %>%
  group_by(node) %>% 
  summarise(ave_rank = mean(rank))

post_rank %>% 
  ggplot(aes(node, rank)) + 
  geom_boxplot() +
  geom_point(data = true_rank,
             mapping = aes(names, f_vec, colour = value)) +
  # geom_point(data = post_mean,
  #            mapping = aes(node, ave_rank, shape = 16),
  #            colour = "blue") +
  # scale_shape_identity() +
  labs(title = "Inferred Latent Ranking with Truth",
       x = "Node", y = "Latent Ranking",
       colour = "Summary") +
  theme(legend.title = element_blank(),
        legend.position = "bottom")
## blue is posterior mean, red is true value
## can add legend to fix this
```

What else should we infer with a larger simulation example? How do we visualise 
the results in this case?

## Stability of Rankings over Time

```{r load_cohort_rankings}
# for(cohort_id in 1:10){
cohort_id <- 5
  start_rank <- readRDS(file = paste(data_path,
                                 "/revisions/rank_stab/", "cohort_",
                                 cohort_id, "start.RDS",
                                 sep = ""))

  end_rank <- readRDS(file = paste(data_path,
                                   "/revisions/rank_stab/", "cohort_",
                                   cohort_id, "end.RDS",
                                   sep = ""))
  ### plot both of these
  init_ranks <- start_rank %>%
    select(starts_with("f")) %>%
    rename_with(~gsub("[", "_", .x, fixed = TRUE)) %>%
    rename_with(~gsub("]", "", .x, fixed = TRUE)) %>%
    pivot_longer(everything(),
                 names_to = "node",
                 values_to = "rank")
  
  final_ranks <- end_rank %>%
    select(starts_with("f")) %>%
    rename_with(~gsub("[", "_", .x, fixed = TRUE)) %>%
    rename_with(~gsub("]", "", .x, fixed = TRUE)) %>%
    pivot_longer(everything(),
                 names_to = "node",
                 values_to = "rank")
  
  init_ranks$node <- factor(init_ranks$node, levels = paste0("f_", 1:12))
  final_ranks$node <- factor(final_ranks$node, levels = paste0("f_", 1:12))
  
  init_ranks$when <- "first14"
  final_ranks$when <- "last14"
  
  init_ranks %>% 
    ggplot(aes(node, rank)) + 
    geom_boxplot() +
    labs(title = "Ranking from first 14 Days")
  
  final_ranks %>% 
    ggplot(aes(node, rank)) + 
    geom_boxplot() +
    labs(title = "Ranking from final 14 Days")
  
  all_ranks <- bind_rows(init_ranks, final_ranks) 
  
  init_ranking <- all_ranks %>% filter(when == "first14") %>% 
  group_by(node) %>% 
  summarise(med = median(rank)) %>% 
  arrange(-med) %>% 
  pull(node)

  ### then set the levels off this
  all_ranks$node <- factor(all_ranks$node, 
                           levels = as.character(init_ranking))
  
  coh_plot <- all_ranks %>% 
    ggplot(aes(node, rank, fill = when)) +
    geom_boxplot() +
    labs(x = "Mouse",
         y = "Latent Rank", 
         fill = "Time Period",
         title = "Agreement between Initial and Final Ranking",
         subtitle = paste0("Cohort ", cohort_id)) +
    scale_fill_discrete(labels = c("First 14 Days", "Final 14 Days"))
  print(coh_plot)
# }

```


### Further Stability Questions

To further investigate the stability of these rankings we 
can do multiple things, including comparing the I&SI scores for both time
periods to see the correlation across time.

```{r compute start-end-isi}
isi_data <- tibble()


for(current_cohort in 1:10) {
  clean_data <- cleanData(full_data[[cohort_names[current_cohort]]])
  return_df <- cleanObservationPeriod(current_cohort, 
                                    full_data[[cohort_names[current_cohort]]],
                                      clean_data)
  start_events <- return_df %>% filter(day <= 14)
  wl_start <- get_wl_matrix(start_events[, c(3, 4)])
  isi_start <- isi98(wl_start)
  start_inf <- tibble(score = isi_start$I + isi_start$SI,
                      order = list(isi_start$best_order),
                      cohort = current_cohort,
                      time = "Start")
  isi_data <- isi_data %>% bind_rows(start_inf)
  end_events <- return_df %>% filter(day > 7)
  wl_end <- get_wl_matrix(end_events[, c(3, 4)])
  isi_end <- isi98(wl_end)
  end_inf <- tibble(score = isi_end$I + isi_end$SI,
                      order = list(isi_end$best_order),
                      cohort = current_cohort,
                      time = "End")
  isi_data <- isi_data %>% 
    bind_rows(end_inf)
}

```


```{r plot_output}
isi_data %>% ggplot(aes(cohort, score, colour = time)) +
  geom_point(alpha = 0.5, show.guide = FALSE) + 
  scale_x_continuous(breaks = 1:10)

### want one row for each cohort
isi_data %>% 
  select(-order) %>% 
  pivot_wider(names_from = time, values_from = score) %>% 
  summarise(correlation = cor(Start, End))

```


## Community Structure Plot

```{r construct_plot, include=FALSE, eval=FALSE}
iAndSI <- function(M) {
  n <- ncol(M)
  result <- rep(0, 2)
  k <- (M - t(M)) / 2
  k[upper.tri(k)] <- 0
  result[1] <- 0
  a <- length(which(k > 0))
  y <- which(k > 0) %% n
  x <- (which(k > 0) - 1) %/% n + 1
  y[y == 0] <- y[y == 0] + n
  if (a > 0) {
    result[1] <- a
    result[2] <- sum(y - x)
  }
  return(result)
}



state_types <- c("total", "utility", "social")
metric_types <- c("dc", "ttri", "i")
state_separation_result <- data.frame(array(0,
                                            c(10 * 
                                                length(state_types) *
                                                length(metric_types),
                                              4)))
colnames(state_separation_result) <- c("cohort", "state", "metric", "value")

total_event_array_lst <- list()
active_event_array_lst <- list()
for (current_cohort in c(1:10)) {
  print(current_cohort)
  load(paste(data_path, 
             cohort_names[current_cohort],
    "/cmmhp_est_zt_",
    cohort_names[current_cohort],
    ".RData",
    sep = ""
  ))
  clean_data <- cleanData(full_data[[cohort_names[current_cohort]]])
  return_df <- cleanObservationPeriod(
    current_cohort, 
    raw_df =  full_data[[cohort_names[current_cohort]]],
    clean_data)
  unique_pairs_df <- return_df %>%
    group_by(initiator, recipient) %>%
    dplyr::summarize(
      count = n(),
      observe = list(observe.id),
      observe.length = list(observe.time),
      no.events = list(no.events)
    )
  unique_observe_win <- unique(return_df[, c("observe.id", "observe.time")])

  expert_rank <- expert_rank_10[[current_cohort]]

  # -------- Load the saved stan result, 
  # -------- plot the inferred parameters and save
  total_event_array_lst[[current_cohort]] <- 
    array(0, dim = c(mice_number, mice_number, max(return_df$observe.id)))
  active_event_array_lst[[current_cohort]] <-
    array(0, dim = c(mice_number, mice_number, max(return_df$observe.id)))

  for (i in 1:mice_number) {
    for (j in 1:mice_number) {
      pair <- which(unique_pairs_df$initiator == i & 
                      unique_pairs_df$recipient == j)
      if (length(pair) > 0 & i!=j) {
        current_window_vec <- unique_pairs_df$observe[[pair]]
        for (cur_win in current_window_vec) {
          row_indicator <- (return_df$initiator == i) & 
            (return_df$recipient == j) &
            (return_df$observe.id == cur_win)
          total_event_array_lst[[current_cohort]][i, j, cur_win] <-
            length(return_df[row_indicator, "event.times"][[1]])
          active_event_array_lst[[current_cohort]][i, j, cur_win] <- 
            sum(apply(2 - state_array_list[[pair]][[cur_win]], 1, mean) > 0.5)
        }
      }
    }
  }

  start_win <- floor(max(return_df$observe.id) / 2)
  end_win <- max(return_df$observe.id)
  matrix1 <- apply(
    total_event_array_lst[[current_cohort]][, , start_win:end_win],
    c(1, 2),
    sum
    )[expert_rank, expert_rank]
  matrix2 <- apply(
    active_event_array_lst[[current_cohort]][, , start_win:end_win],
    c(1, 2),
    sum
    )[expert_rank, expert_rank]
  matrix3 <- apply(
    total_event_array_lst[[current_cohort]][, , start_win:end_win] -
      active_event_array_lst[[current_cohort]][, , start_win:end_win],
    c(1, 2),
    sum
    )[expert_rank, expert_rank]

  # ------ compute metrics ------
  state_separation_result$cohort[
    ((current_cohort - 1) * 
      length(metric_types) *
      length(state_types) + 1):(current_cohort * length(metric_types) *
                                  length(state_types))] <-
    cohort_names[current_cohort]
  state_separation_result$metric[
    ((current_cohort - 1) *
       length(metric_types) *
       length(state_types) + 1):(current_cohort * length(metric_types) *
                                   length(state_types))] <- 
    rep(c("dc", "ttri", "i"), length(state_types))

  state_separation_result$state[
    ((current_cohort - 1) *
       length(metric_types) *
       length(state_types) + 1):(current_cohort * length(metric_types) *
                                   length(state_types) -
                                   length(metric_types) * 2)] <- "total"
  
  ## bug below here need to find iAndSI
  state_separation_result$value[
    ((current_cohort - 1) *
       length(metric_types) *
       length(state_types) + 1):(current_cohort * length(metric_types) *
                                   length(state_types) - 
                                   length(metric_types) * 2)] <- 
    c(dci(matrix1), ttri(matrix1)[[2]], iAndSI(matrix1)[1])

  state_separation_result$state[
    ((current_cohort - 1) *
       length(metric_types) *
       length(state_types) + 
       length(metric_types) + 1):(current_cohort * 
                                    length(metric_types) *
                                    length(state_types) -
                                    length(metric_types))] <-
    "utility"
  state_separation_result$value[
    ((current_cohort - 1) *
       length(metric_types) * 
       length(state_types) + 
       length(metric_types) + 1):(current_cohort * length(metric_types)
                                  * length(state_types)
                                  - length(metric_types))] <-
    c(dci(matrix2), ttri(matrix2)[[2]], iAndSI(matrix2)[1])

  state_separation_result$state[(current_cohort * length(metric_types) *
                                   length(state_types) - 
                                   length(metric_types) + 1):(
                                     current_cohort * length(metric_types) *
                                       length(state_types))] <- "social"
  state_separation_result$value[(current_cohort * length(metric_types) *
                                   length(state_types) -
                                   length(metric_types) + 1):(
                                     current_cohort * length(metric_types) *
                                       length(state_types))] <- 
    c(dci(matrix3), ttri(matrix3)[[2]], iAndSI(matrix3)[1])
  rm(interpolation_array_list)
  rm(state_array_list)
}

save(state_types, metric_types, state_separation_result,
  total_event_array_lst, active_event_array_lst,
  file = "../output/state_separation_plot.RData"
)

```


```{r recreate_jing_figure, message=FALSE}
load("../output/state_separation_plot.RData")
# for (current_cohort in c(1)) {
  current_cohort <- 9
  total_event_array <- total_event_array_lst[[current_cohort]]
  active_event_array <- active_event_array_lst[[current_cohort]]
  clean_data <- cleanData(full_data[[cohort_names[current_cohort]]])
  return_df <- cleanObservationPeriod(current_cohort, 
                                    full_data[[cohort_names[current_cohort]]],
                                      clean_data)

  start_win <- floor(max(return_df$observe.id) / 3) * (0:2) + 1
  end_win <- floor(max(return_df$observe.id) / 3) * (1:3)
  matrix1 <- apply(
    total_event_array[, , start_win[1]:end_win[1]] -
      active_event_array[, , start_win[1]:end_win[1]],
    c(1, 2), sum
  )
  matrix2 <- apply(
    total_event_array[, , start_win[2]:end_win[2]] -
      active_event_array[, , start_win[2]:end_win[2]],
    c(1, 2), sum
  )
  matrix3 <- apply(
    total_event_array[, , start_win[3]:end_win[3]] -
      active_event_array[, , start_win[3]:end_win[3]],
    c(1, 2), sum
  )
  ### work to here
  g_community1 <- graph_from_adjacency_matrix(matrix1, mode = "undirected")
  lec1 <- cluster_leading_eigen(g_community1)

  g_community2 <- graph_from_adjacency_matrix(matrix2, mode = "undirected")
  lec2 <- cluster_leading_eigen(g_community2)

  g_community3 <- graph_from_adjacency_matrix(matrix3, mode = "undirected")
  lec3 <- cluster_leading_eigen(g_community3)

  ### Make plot for t=1
  # png(paste(plot_path, "real_clustering_1.png", sep = ""), 
  #     height = 600,
  #     width = 600)
  myCircularPlot(
    cur.matrix = matrix1,
    ## is the ordering here for the nodes? need to make sure I get this right
    ## working off this being the ordering from the clustering above
    # cur.order = c(1, 4, 10, 5, 11, 6, 7, 2, 8, 12, 9, 3),
    cur.order = order(lec1$membership),
    cur.color = c(
      colorRampPalette(brewer.pal(
        name = "YlOrBr",
        n = 8))(14)[c(13, 11, 9, 7)],
      colorRampPalette(brewer.pal(
        name = "PuRd",
        n = 8))(13)[c(4, 6, 8, 10, 12)],
      colorRampPalette(brewer.pal(
        name = "Blues",
        n = 8))(15)[c(4, 8, 12)]
    ),
    cur.gap = c(rep(5, 3), 30, rep(5, 4), 30, rep(5, 2), 30)
  )
  # dev.off()

  ### Make plot for t=2
 #  png(paste(plot_path, "real_clustering_2.png", sep = ""),
 #   height = 600,
 #   width = 600
 # )
 # problems with these 2, possibly if no events from 11?
 circos.par$cell.padding <- c(0,0,0,0)
 myCircularPlot(
   cur.matrix = matrix2[-11,-11],
   cur.order = order(lec2$membership)[-6],
   cur.color = c(
     colorRampPalette(brewer.pal(
       name = "YlOrBr",
       n = 8))(16)[c(15, 13, 11, 9, 7, 5)],
     colorRampPalette(brewer.pal(
       name = "Blues",
       n = 8))(15)[c(6, 8, 10, 12, 14)]
   ),
   cur.gap = c(rep(5, 5), 30, rep(5, 4), 30),
   cur.ID = c(1:12)[-11]
 )
 # dev.off()

  ### Make plot for t=3
  # png(paste(plot_path, "real_clustering_3.png", sep = ""),
  #     height = 600,
  #     width = 600)
  myCircularPlot(
    cur.matrix = matrix3[-11, -11],
    cur.order = order(lec3$membership)[-4],
    cur.color = c(
      colorRampPalette(
        brewer.pal(name = "YlOrBr",
                   n = 8))(14)[c(13, 9, 5, 3)],
      colorRampPalette(brewer.pal(
        name = "Blues",
        n = 8))(16)[c(9, 11, 13, 15)],
      colorRampPalette(brewer.pal(
        name = "PuRd",
        n = 8))(15)[c(4, 8, 12)]
    ),
    cur.gap = c(rep(5, 3), 30, rep(5, 3), 30, rep(5, 2), 30),
    cur.ID = c(1:12)[-11]
  )
  # dev.off()
# }
```

```{r get-days-above-plot}
clean_data <- cleanData(full_data[[cohort_names[current_cohort]]])
return_df <- cleanObservationPeriod(
  current_cohort, 
  raw_df =  full_data[[cohort_names[current_cohort]]],
  clean_data)
unique_pairs_df <- return_df %>%
  group_by(initiator, recipient) %>%
  dplyr::summarize(
    count = n(),
    observe = list(observe.id),
    observe.length = list(observe.time),
    no.events = list(no.events)
  )
unique_observe_days <- unique(return_df[, 
                                       c("observe.id", "observe.time", "day")])

start_winds <- unique_observe_days %>% 
  filter(observe.id %in% start_win)

end_winds <-unique_observe_days %>% 
  filter(observe.id %in% end_win)


```


### Get within/between cluster fights for this

```{r extract-from-previons}
wind1_memb <- tibble(id = 1:12, memb = lec1$membership)

return_df %>% 
  filter(observe.id >= start_winds$observe.id[1]) %>% 
  filter(observe.id <= end_winds$observe.id[1]) %>% 
  ### join with wind1_memb, tally
  left_join(wind1_memb, by = c("initiator" = "id")) %>% 
  left_join(wind1_memb, by = c("recipient" = "id")) %>% 
  rename(send_clust = memb.x, 
         rec_clust = memb.y) %>% 
  group_by(send_clust, rec_clust) %>% 
  summarise(num_events = sum(no.events)) %>% 
  mutate(clust = if_else(send_clust == rec_clust, "internal", "external")) %>% 
  group_by(clust) %>% 
  summarise(events = sum(num_events)) %>% 
  ungroup() %>% 
  mutate(prop = events/sum(events))


wind2_memb <- tibble(id = 1:12, memb = lec2$membership)

return_df %>% 
  filter(observe.id >= start_winds$observe.id[2]) %>% 
  filter(observe.id <= end_winds$observe.id[2]) %>% 
  ### join with wind1_memb, tally
  left_join(wind2_memb, by = c("initiator" = "id")) %>% 
  left_join(wind2_memb, by = c("recipient" = "id")) %>% 
  rename(send_clust = memb.x, 
         rec_clust = memb.y) %>% 
  group_by(send_clust, rec_clust) %>% 
  summarise(num_events = sum(no.events)) %>% 
  mutate(clust = if_else(send_clust == rec_clust, "internal", "external")) %>% 
  group_by(clust) %>% 
  summarise(events = sum(num_events)) %>% 
  ungroup() %>% 
  mutate(prop = events/sum(events))

wind3_memb <- tibble(id = 1:12, memb = lec3$membership)

return_df %>% 
  filter(observe.id >= start_winds$observe.id[3]) %>% 
  filter(observe.id <= end_winds$observe.id[3]) %>% 
  ### join with wind1_memb, tally
  left_join(wind3_memb, by = c("initiator" = "id")) %>% 
  left_join(wind3_memb, by = c("recipient" = "id")) %>% 
  rename(send_clust = memb.x, 
         rec_clust = memb.y) %>% 
  group_by(send_clust, rec_clust) %>% 
  summarise(num_events = sum(no.events)) %>% 
  mutate(clust = if_else(send_clust == rec_clust, "internal", "external")) %>% 
  group_by(clust) %>% 
  summarise(events = sum(num_events)) %>% 
  ungroup() %>% 
  mutate(prop = events/sum(events))

```



```{r repeat-all-cohorts}

get_inter_ext_events <- function(current_cohort) {
  total_event_array <- total_event_array_lst[[current_cohort]]
  active_event_array <- active_event_array_lst[[current_cohort]]
  clean_data <- cleanData(full_data[[cohort_names[current_cohort]]])
  return_df <- cleanObservationPeriod(current_cohort, 
                                    full_data[[cohort_names[current_cohort]]],
                                      clean_data)
  
  start_win <- floor(max(return_df$observe.id) / 3) * (0:2) + 1
  end_win <- floor(max(return_df$observe.id) / 3) * (1:3)
  matrix1 <- apply(
    total_event_array[, , start_win[1]:end_win[1]] -
      active_event_array[, , start_win[1]:end_win[1]],
    c(1, 2), sum
  )
  matrix2 <- apply(
    total_event_array[, , start_win[2]:end_win[2]] -
      active_event_array[, , start_win[2]:end_win[2]],
    c(1, 2), sum
  )
  matrix3 <- apply(
    total_event_array[, , start_win[3]:end_win[3]] -
      active_event_array[, , start_win[3]:end_win[3]],
    c(1, 2), sum
  )
  
  g_community1 <- graph_from_adjacency_matrix(matrix1, mode = "undirected")
  lec1 <- cluster_leading_eigen(g_community1)
  
  g_community2 <- graph_from_adjacency_matrix(matrix2, mode = "undirected")
  lec2 <- cluster_leading_eigen(g_community2)
  
  g_community3 <- graph_from_adjacency_matrix(matrix3, mode = "undirected")
  lec3 <- cluster_leading_eigen(g_community3)
  
  wind1_memb <- tibble(id = 1:12, memb = lec1$membership)
  
  return_df %>% 
    filter(observe.id >= start_winds$observe.id[1]) %>% 
    filter(observe.id <= end_winds$observe.id[1]) %>% 
    ### join with wind1_memb, tally
    left_join(wind1_memb, by = c("initiator" = "id")) %>% 
    left_join(wind1_memb, by = c("recipient" = "id")) %>% 
    rename(send_clust = memb.x, 
           rec_clust = memb.y) %>% 
    group_by(send_clust, rec_clust) %>% 
    summarise(num_events = sum(no.events)) %>% 
    mutate(clust = if_else(send_clust == rec_clust, "internal", "external")) %>% 
    group_by(clust) %>% 
    summarise(events = sum(num_events)) %>% 
    ungroup() %>% 
    mutate(prop = events/sum(events))
  
  
  wind2_memb <- tibble(id = 1:12, memb = lec2$membership)
  
  return_df %>% 
    filter(observe.id >= start_winds$observe.id[2]) %>% 
    filter(observe.id <= end_winds$observe.id[2]) %>% 
    ### join with wind1_memb, tally
    left_join(wind2_memb, by = c("initiator" = "id")) %>% 
    left_join(wind2_memb, by = c("recipient" = "id")) %>% 
    rename(send_clust = memb.x, 
           rec_clust = memb.y) %>% 
    group_by(send_clust, rec_clust) %>% 
    summarise(num_events = sum(no.events)) %>% 
    mutate(clust = if_else(send_clust == rec_clust, "internal", "external")) %>% 
    group_by(clust) %>% 
    summarise(events = sum(num_events)) %>% 
    ungroup() %>% 
    mutate(prop = events/sum(events))
  
  wind3_memb <- tibble(id = 1:12, memb = lec3$membership)
  
  return_df %>% 
    filter(observe.id >= start_winds$observe.id[3]) %>% 
    filter(observe.id <= end_winds$observe.id[3]) %>% 
    ### join with wind1_memb, tally
    left_join(wind3_memb, by = c("initiator" = "id")) %>% 
    left_join(wind3_memb, by = c("recipient" = "id")) %>% 
    rename(send_clust = memb.x, 
           rec_clust = memb.y) %>% 
    group_by(send_clust, rec_clust) %>% 
    summarise(num_events = sum(no.events)) %>% 
    mutate(clust = if_else(send_clust == rec_clust, "internal", "external")) %>% 
    group_by(clust) %>% 
    summarise(events = sum(num_events)) %>% 
    ungroup() %>% 
    mutate(prop = events/sum(events))

   
}


get_inter_ext_events(current_cohort = 2)

```

# Repeat Rank Simulations

```{r rank-with-20-nodes}
sim_files <- list.files(here("output", "revisions", "rank_sims"), 
                        pattern = "rank_sim")

all_sims <- list()
for(i in seq_along(sim_files)) {
 single_fit <- readRDS(here("output",
                            "revisions",
                            "rank_sims",
                            sim_files[i]))
 all_sims[[i]] <- single_fit
}

spear <- function(sim_data) {
  truth <- sim_data$truth
  sim_data %>%
    select(m1:glicko) %>%
    purrr::map( ~cor.test(truth, .x,
                   method = "spearman")$estimate  ) %>%
    enframe() %>%
    unnest(cols = c(value))
}


sim_data <- map_dfr(all_sims, spear) 

name <- sim_data$name

sim_data$name <- case_when(
          name == "isi" ~ "I&SI",
          name == "m1" ~ "C-HP",
          name == "m2" ~ "C-DCHP",
          name == "m3" ~ "C-MMHP",
          name == "agg" ~ "AggRank",
          name == "glicko" ~ "Glicko")

sim_data$name <- factor(sim_data$name, levels = c("I&SI",
                                                  "AggRank",
                                                  "Glicko",
                                                  "C-HP",
                                                  "C-DCHP",
                                                  "C-MMHP"))

plot_cols <- col_df %>% filter(method %in% levels(sim_data$name)) %>%
  pull(cols)
  
sim_data %>%
  rename(Method = name, corr = value) %>%
  ggplot(aes(Method,corr)) + 
  geom_boxplot(aes(fill = Method), alpha = 0.7) +
  scale_fill_manual(values = plot_cols) +
  labs(y = "Rank Correlation") + theme_bw() +
  theme(plot.title = element_text(size = 22, hjust = 0.5, face="bold"),
        text = element_text(size = 20),
        axis.text.x=element_blank(),
        axis.ticks.x = element_blank(),
        legend.position="right") + ggtitle("(b)")

```


# Improve Fig 4b

Trying to write a better version of Figure 4b using these new larger
simulated networks.

```{r process-new-4b}
plot.s <- 2 # 7 is pretty good, prev 1
plot.i <- 20  ## prev 20
plot.j <- 16  ## prev 15

cur_i <- plot.i
cur_j <- plot.j



load(paste0(here("output", "revisions", "sim_m3"),
  "/", "sim_model3_fit123_",
  plot.s,
  ".RData"
))


test.mmhp <- sim_model3_data$mmhp_matrix[plot.i, plot.j][[1]]
temp.t <- test.mmhp$tau
current.n <- length(temp.t) - 1
time.segment <- seq(0, tail(temp.t, 1), length.out = 5000)

### Preprocess the model inference result
## model 1
#########

## get f from cmdstan 

f_draws <- sim_model3_stan_sim1 %>% 
  select(starts_with("f"))

model1_par_est <- list(
  lambda0 = mean(sim_model3_stan_sim1$lambda0),
  eta_1 =
    mean(sim_model3_stan_sim1$eta_1),
  eta_2 =
    mean(sim_model3_stan_sim1$eta_2),
  eta_3 =
    mean(sim_model3_stan_sim1$eta_3),
  beta = mean(sim_model3_stan_sim1$beta),
  f = apply(f_draws, 2, mean)
)
lambda.m1 <- uniHawkesIntensityNumeric(
  object = list(
    lambda0 =
      model1_par_est$lambda0,
    alpha =
      model1_fn$alpha.fun(
        model1_par_est$f[plot.i],
        model1_par_est$f[plot.j],
        model1_par_est$eta_1,
        model1_par_est$eta_2,
        model1_par_est$eta_3
      ),
    beta = model1_par_est$beta
  ),
  events = temp.t,
  time.vec = time.segment
)


## model2
#############
gamma_draws <- sim_model3_stan_sim2 %>% 
  select(starts_with("gamma"))

zeta_draws <- sim_model3_stan_sim2 %>% 
  select(starts_with("zeta"))

f_draws <- sim_model3_stan_sim2 %>% 
  select(starts_with("f"))

model2_par_est <- list(
  gamma = apply(gamma_draws, 2, mean),
  zeta = apply(zeta_draws, 2, mean),
  eta_1 = mean(sim_model3_stan_sim2$eta_1),
  eta_2 = mean(sim_model3_stan_sim2$eta_2),
  eta_3 = mean(sim_model3_stan_sim2$eta_3),
  beta = mean(sim_model3_stan_sim2$beta),
  f = apply(f_draws, 2, mean)
)

lambda.m2 <- uniHawkesIntensityNumeric(
  object = list(
    lambda0 = model2_par_est$gamma[plot.i] +
      model2_par_est$zeta[plot.j],
    alpha = model1_fn$alpha.fun(
      model2_par_est$f[plot.i],
      model2_par_est$f[plot.j],
      model2_par_est$eta_1,
      model2_par_est$eta_2,
      model2_par_est$eta_3
    ),
    beta = model2_par_est$beta
  ),
  events = temp.t,
  time.vec = time.segment
)

## Model3
###

lam0_draws <- sim_model3_stan_sim3 %>% 
  select(starts_with("gamma"))

lam1_draws <- sim_model3_stan_sim3 %>% 
  select(starts_with("zeta"))

gamma_draws <- sim_model3_stan_sim3 %>% 
  select(starts_with("gamma"))

zeta_draws <- sim_model3_stan_sim3 %>% 
  select(starts_with("zeta"))

f_draws <- sim_model3_stan_sim2 %>% 
  select(starts_with("f"))


lam0_vec <- apply(lam0_draws, 2, mean)
lam1_vec <- apply(lam1_draws, 2, mean)
lam0_par_est <- matrix(0,
  nrow = length(object_par$f_vec_1),
  ncol = length(object_par$f_vec_1)
)
lam1_par_est <- matrix(0,
  nrow = length(object_par$f_vec_1),
  ncol = length(object_par$f_vec_1)
)

clean_sim_data <- cleanSimulationData(
  raw_data = sim_model3_data,
  cut_off = cut_off,
  N = length(object_par$f_vec_1)
)

for (i in seq_along(lam0_vec)) {
  row_id <- clean_sim_data$I_fit[i]
  col_id <- clean_sim_data$J_fit[i]
  lam0_par_est[row_id, col_id] <- lam0_vec[i]
  lam1_par_est[row_id, col_id] <- lam1_vec[i]
}


###

#############
mmhp_par_est <- list(
  lambda0 = lam0_par_est,
  lambda1 = lam1_par_est,
  eta_1 = mean(sim_model3_stan_sim3$eta_1),
  eta_2 = mean(sim_model3_stan_sim3$eta_2),
  eta_3 = mean(sim_model3_stan_sim3$eta_3),
  beta = mean(sim_model3_stan_sim3$beta),
  f = apply(f_draws, 2, mean)
)

object_hat <- list(
  lambda0 = mmhp_par_est$lambda0[cur_i, cur_j],
  lambda1 = mmhp_par_est$lambda1[cur_i, cur_j],
  alpha = model3_fn$alpha.fun(
    mmhp_par_est$f[cur_i],
    mmhp_par_est$f[cur_j],
    mmhp_par_est$eta_1,
    mmhp_par_est$eta_2
  ),
  beta = mmhp_par_est$beta,
  q1 = model3_fn$q1.fun(
    mmhp_par_est$f[cur_i],
    mmhp_par_est$f[cur_j],
    mmhp_par_est$eta_3
  ),
  q2 = model3_fn$q0.fun(
    mmhp_par_est$f[cur_i],
    mmhp_par_est$f[cur_j],
    mmhp_par_est$eta_3
  )
)

## then need to load in the state estimate here
load(paste0(here("output", "revisions", "sim_m3"),
  "/", "fit123_state_est_",
  plot.s,
  ".RData"
))

state.est.latent.mmhp <- interpolate_state_est_lst[plot.i, plot.j][[1]]
state.est.latent.mmhp.new <- fixInterpolateState(state.est.latent.mmhp,
  termination = 200
)

step.fun.est <- stepfun(
  state.est.latent.mmhp$x.hat,
  2 - state.est.latent.mmhp$z.hat
)

lambda.m3 <- mmhpIntensityNumeric(
  params = object_hat,
  t = temp.t[-1],
  time.vec = time.segment,
  latent.vec = step.fun.est(time.segment)
)

object_true <- lapply(object_matrix, function(x) x[plot.i, plot.j])
names(object_true) <- c("lambda0", "lambda1", "alpha", "beta", "q1", "q2")

lambda.true <- mmhpTrueIntensityNumeric(
  params = object_true,
  t = temp.t,
  latent = list(
    x = fixStateTransition(test.mmhp)$x,
    z = fixStateTransition(test.mmhp)$z
  ),
  time.vec = time.segment
)

```


```{r fig4b-redone}
mmhp_lty <- 1

y.ub <- c(8, 8, 8) # c(130,72,31)
x_events <- 190 # 135#150
my.xlim <- 200 # 160#200#130
my.long.x <- 205 # 205#134.5
legend.x <- c(100, 100, 100) # c(135,135,135)
legend.y <- # c(34,32,32)
legend.y <- c(6, 6, 6) # c(15,12,15)#c(62,37,18)#c(22,22,22)
legend.cex <- 1.5 # 3
line.alpha <- c(1, 0.5)
line.wdth <- c(1.5, 2)
negative.col <- add.alpha("lightskyblue")
positive.col <- add.alpha("tomato")


model_colors <- col_df %>% filter(method %in% c(
  "C-HP",
  "C-DCHP",
  "C-MMHP"
))

model_colors <- model_colors %>% pull(cols)

# model1
############
true.object <- object_true

```



```{r actual-plot}
layout(matrix(c(1:6), 6, 1), heights = rep(c(7.5, 2.5), 3))
par(
  mar = c(0, 0.3, 0, 0.1), oma = c(0, 3.5, 4, 0),
  tcl = 0.2, mgp = c(0.5, 0, 0), xpd = TRUE
)

mmhp_est <- fixStateTransition(test.mmhp)

drawUniMMHPIntensityPaper(true.object,
                          simulation = mmhp_est,
                          yupper = y.ub[1],
                          color = add.alpha("black", alpha = line.alpha[1]),
                          line.width = line.wdth[1],
                          y.ratio = -0.05, min.y = -0.5,
                          min.x = 0, max.x = my.xlim,
                          title_name = paste(plot.i, "->", plot.j),
                          title.cex = 2,
                          box.type = "n",
                          line_type = mmhp_lty
)
drawHawkesIntensityPaper(
  lambda0 = model1_par_est$lambda0,
  alpha = model1_fn$alpha.fun(
    model1_par_est$f[plot.i],
    model1_par_est$f[plot.j],
    model1_par_est$eta_1,
    model1_par_est$eta_2,
    model1_par_est$eta_3
  ),
  beta = model1_par_est$beta,
  events = test.mmhp$tau,
  color = add.alpha(model_colors[1],
                    alpha = line.alpha[2]
  ),
  line.width = line.wdth[2]
)

# draw box
axis(1,
     at = c(-2, my.long.x),
     col = "gray35",
     line = 0.5,
     tick = T,
     labels = rep("", 2),
     lwd = 0.5,
     lwd.ticks = 0,
     lty = 3
)


## add legend
# changed 34 to 23, 25 to 18, -20 to -10
# legend(10,legend.y[1],c("State 1/0 events","State change point"),
#        col = c(NA,"red"),
#        y.intersp=0.85,x.intersp=-0.1, bty = "n",
#        pch = c(NA,4), pt.cex = c(NA,2), cex=legend.cex,
#        lty = c(NA,NA), lwd=c(NA,4))
# points(29,84,pch=1,cex=2,col="blue")
# points(26,84,pch=16,cex=2,col="blue")

#### more legend
legend(legend.x[1] - 2, legend.y[1] + 1, c("True"),
       col = c("black"),
       y.intersp = 0.88, x.intersp = 0.65, bty = "n",
       lty = c(1), lwd = c(5), cex = legend.cex, seg.len = 1
)
legend(legend.x[1] + 22, legend.y[1] + 1, c("C-HP"),
       col = c(model_colors[1]),
       y.intersp = 0.88, x.intersp = 0.65, bty = "n",
       lty = c(1), lwd = c(5), cex = legend.cex, seg.len = 1
)

## delta lambda
par(mar = c(0, 0.3, 0, 0.1))
plot(0, 0,
     xlim = c(0, my.xlim), 
     ylim = c(-0.5, 4),
     type = "n",
     bty = "n",
     xlab = "",
     ylab = "",
     xaxt = "n",
     yaxt = "n",
     axes = FALSE
)
delta.lambda <- lambda.m1$lambda.t - lambda.true$lambda.t
delta.positive <- delta.lambda
delta.positive[delta.positive < 0] <- 0
delta.negative <- delta.lambda
delta.negative[delta.negative > 0] <- 0
### hiding these for now ###
polygon(c(0, lambda.true$time.vec, x_events), # 200
        c(0, delta.negative, 0),
        col = negative.col, border = NA
)
polygon(c(0, lambda.true$time.vec, x_events), # 200
        c(0, delta.positive, 0),
        col = positive.col, border = NA
)

axis(1,
     at = c(-1, my.long.x), 
     col = "gray35",
     line = 0, tick = T, 
     labels = rep("", 2),
     lwd = 0.7,
     lwd.ticks = 0
)

# model2
############
drawUniMMHPIntensityPaper(true.object,
                          simulation = mmhp_est,
                          ### these points aren't consistent?
                          yupper = y.ub[2],
                          color = add.alpha("black",
                                            alpha = line.alpha[1]),
                          line.width = line.wdth[1],
                          y.ratio = -0.05,
                          min.y = -0.5,
                          min.x = 0,
                          max.x = my.xlim,
                          box.type = "n",
                          line_type = mmhp_lty
)
drawHawkesIntensityPaper(
  lambda0 = model2_par_est$gamma[plot.i] +
    model2_par_est$zeta[plot.j],
  alpha = model1_fn$alpha.fun(
    model2_par_est$f[plot.i],
    model2_par_est$f[plot.j],
    model2_par_est$eta_1,
    model2_par_est$eta_2,
    model2_par_est$eta_3
  ),
  beta = model2_par_est$beta,
  events = test.mmhp$tau,
  color = add.alpha(model_colors[2],
                    alpha = line.alpha[2]
  ),
  line.width = line.wdth[2]
)

### used legend
legend(legend.x[2] - 2, legend.y[2] + 1, c("True"),
       col = c("black"),
       y.intersp = 0.88, x.intersp = 0.65, bty = "n",
       lty = c(1), lwd = c(5), cex = legend.cex, seg.len = 1
)
legend(legend.x[2] + 22, legend.y[2] + 1, "C-DCHP",
       col = model_colors[2],
       y.intersp = 0.88,
       x.intersp = 0.65,
       bty = "n",
       lty = 1,
       lwd = 5,
       cex = legend.cex,
       seg.len = 1
)

axis(1,
     at = c(-2, my.long.x),
     col = "gray35",
     line = 0.5,
     tick = T,
     labels = rep("", 2),
     lwd = 0.5,
     lwd.ticks = 0,
     lty = 3
)


## location of legend
legend(legend.x[2] - 95,
       legend.y[2] + 2, c("State 0/1 events", "State change point"),
       col = c(NA, "red"),
       y.intersp = 0.85,
       x.intersp = -0,
       bty = "n",
       pch = c(NA, 4), pt.cex = c(NA, 2), cex = legend.cex,
       lty = c(NA, NA), lwd = c(NA, 2)
)
points(legend.x[2] - 89, legend.y[2], 
       pch = 1, cex = 2, col = "blue")
points(legend.x[2] - 85, legend.y[2],
       pch = 16, cex = 2, col = "blue")

## delta lambda
par(mar = c(0, 0.3, 0, 0.1))
delta.lambda <- lambda.m2$lambda.t - lambda.true$lambda.t

plot(lambda.true$time.vec, delta.lambda,
     xlim = c(0, my.xlim),
     ylim = c(-0.5, 4), type = "n",
     bty = "n",
     xlab = "",
     ylab = "",
     xaxt = "n",
     yaxt = "n",
     axes = FALSE
)
delta.lambda <- lambda.m2$lambda.t - lambda.true$lambda.t
delta.positive <- delta.lambda
delta.positive[delta.positive < 0] <- 0
delta.negative <- delta.lambda
delta.negative[delta.negative > 0] <- 0
polygon(c(0, lambda.true$time.vec, x_events), # 200
        c(0, delta.negative, 0),
        col = negative.col, border = NA
)
polygon(c(0, lambda.true$time.vec, x_events), # 200
        c(0, delta.positive, 0),
        col = positive.col, border = NA
)
# segments(0,0,my.xlim,0,col="gray45")
## draw box
axis(1,
     at = c(-2, my.long.x), col = "gray35",
     line = 0, tick = T, labels = rep("", 2), lwd = 0.7, lwd.ticks = 0
)


# model3
########
par(mar = c(0, 0.3, 1, 0.1))
drawUniMMHPIntensityPaper(true.object,
                          simulation = mmhp_est,
                          yupper = y.ub[3],
                          color = add.alpha("black", alpha = line.alpha[1]),
                          line.width = line.wdth[1],
                          y.ratio = -0.05, min.y = -0.5,
                          min.x = 0, max.x = my.xlim,
                          box.type = "n", line_type = mmhp_lty
)
drawUniMMHPIntensityPaper(object_hat,
                          simulation = list(
                            x = state.est.latent.mmhp.new$x.hat,
                            z = state.est.latent.mmhp.new$z.hat,
                            tau = test.mmhp$tau, zt = test.mmhp$zt,
                            lambda.max = test.mmhp$lambda.max
                          ),
                          yupper = y.ub, add = TRUE,
                          color = add.alpha(model_colors[3],
                                            alpha = line.alpha[2]
                          ),
                          line.width = line.wdth[2]
)
legend(legend.x[3] - 2, legend.y[3] + 1, c("True"),
       col = c("black"),
       y.intersp = 0.88, x.intersp = 0.65, bty = "n",
       lty = c(1), lwd = c(5), cex = legend.cex, seg.len = 1
)


legend(legend.x[3] + 22, legend.y[3] + 1, "C-MMHP",
       col = model_colors[3],
       y.intersp = 0.88,
       x.intersp = .65,
       bty = "n",
       lty = 1,
       lwd = 5,
       cex = legend.cex,
       seg.len = 1
)
## draw box
axis(1,
     at = c(-2, my.long.x),
     col = "gray35",
     line = 0.5,
     tick = T,
     labels = rep("", 2), 
     lwd = 0.5,
     lwd.ticks = 0, lty = 3
)

legend(legend.x[3] - 95, legend.y[3] + 2,
       c("Overestimation", "Underestimation"),
       col = c(positive.col, negative.col),
       y.intersp = 0.75, x.intersp = 0.5, bty = "n",
       lty = c(1, 1), lwd = c(10, 10), cex = legend.cex, seg.len = 0.8
)

## delta lambda
par(mar = c(0, 0.3, 0, 0.1))
plot(0, 0,
     xlim = c(0, my.xlim), 
     ylim = c(-0.5, 4), type = "n",
     bty = "n", xlab = "", ylab = "", xaxt = "n", yaxt = "n",
     axes = FALSE
)
delta.lambda <- lambda.m3 - lambda.true$lambda.t
delta.positive <- delta.lambda
delta.positive[delta.positive < 0] <- 0
delta.negative <- delta.lambda
delta.negative[delta.negative > 0] <- 0
### hiding these for now
polygon(c(0, lambda.true$time.vec, x_events), # 200
        c(0, delta.negative, 0),
        col = negative.col, border = NA
)
polygon(c(0, lambda.true$time.vec, x_events), # 200
        c(0, delta.positive, 0),
        col = positive.col, border = NA
)
# segments(0,0,my.xlim,0,col="gray45")
## draw box
axis(1,
     at = c(-2, my.long.x), col = "gray35",
     line = 0, tick = T, labels = rep("", 2), lwd = 0.7, lwd.ticks = 0
)


## top
mtext(text = "(b)", side = 3, line = 0.8,
      outer = TRUE, cex = 2.5, font = 2)
## bottom
mtext(text = "Time", side = 1, line = 2,
      outer = TRUE, cex = 2.25)
## left
mtext(text = "Intensity", side = 2,
      line = 0.6, outer = TRUE, cex = 2.25)
```



Let's try find the best pairs
```{r identify-best-fig4b}
plot.s <- 2 # 7 is pretty good

load(paste0(here("output", "revisions", "sim_m3"),
  "/", "sim_model3_fit123_",
  plot.s,
  ".RData"
))

# 
# plot.i <- 19  ## prev 20
# plot.j <- 15  ## prev 15
# 
# cur_i <- plot.i
# cur_j <- plot.j


for(plot.i in 20:15){
  for(plot.j in 20:15){
    if(plot.i != plot.j) {
      cat("i is ", plot.i, ", j is ", plot.j, " \n")
      test.mmhp <- sim_model3_data$mmhp_matrix[plot.i, plot.j][[1]]
      temp.t <- test.mmhp$tau
      current.n <- length(temp.t) - 1
      time.segment <- seq(0, tail(temp.t, 1), length.out = 5000)
      
      ### Preprocess the model inference result
      ## model 1
      #########
      
      ## get f from cmdstan 
      
      f_draws <- sim_model3_stan_sim1 %>% 
        select(starts_with("f"))
      
      model1_par_est <- list(
        lambda0 = mean(sim_model3_stan_sim1$lambda0),
        eta_1 =
          mean(sim_model3_stan_sim1$eta_1),
        eta_2 =
          mean(sim_model3_stan_sim1$eta_2),
        eta_3 =
          mean(sim_model3_stan_sim1$eta_3),
        beta = mean(sim_model3_stan_sim1$beta),
        f = apply(f_draws, 2, mean)
      )
      lambda.m1 <- uniHawkesIntensityNumeric(
        object = list(
          lambda0 =
            model1_par_est$lambda0,
          alpha =
            model1_fn$alpha.fun(
              model1_par_est$f[plot.i],
              model1_par_est$f[plot.j],
              model1_par_est$eta_1,
              model1_par_est$eta_2,
              model1_par_est$eta_3
            ),
          beta = model1_par_est$beta
        ),
        events = temp.t,
        time.vec = time.segment
      )
      
      
      ## model2
      #############
      gamma_draws <- sim_model3_stan_sim2 %>% 
        select(starts_with("gamma"))
      
      zeta_draws <- sim_model3_stan_sim2 %>% 
        select(starts_with("zeta"))
      
      f_draws <- sim_model3_stan_sim2 %>% 
        select(starts_with("f"))
      
      model2_par_est <- list(
        gamma = apply(gamma_draws, 2, mean),
        zeta = apply(zeta_draws, 2, mean),
        eta_1 = mean(sim_model3_stan_sim2$eta_1),
        eta_2 = mean(sim_model3_stan_sim2$eta_2),
        eta_3 = mean(sim_model3_stan_sim2$eta_3),
        beta = mean(sim_model3_stan_sim2$beta),
        f = apply(f_draws, 2, mean)
      )
      
      lambda.m2 <- uniHawkesIntensityNumeric(
        object = list(
          lambda0 = model2_par_est$gamma[plot.i] +
            model2_par_est$zeta[plot.j],
          alpha = model1_fn$alpha.fun(
            model2_par_est$f[plot.i],
            model2_par_est$f[plot.j],
            model2_par_est$eta_1,
            model2_par_est$eta_2,
            model2_par_est$eta_3
          ),
          beta = model2_par_est$beta
        ),
        events = temp.t,
        time.vec = time.segment
      )
      
      ## Model3
      ###
      
      lam0_draws <- sim_model3_stan_sim3 %>% 
        select(starts_with("gamma"))
      
      lam1_draws <- sim_model3_stan_sim3 %>% 
        select(starts_with("zeta"))
      
      gamma_draws <- sim_model3_stan_sim3 %>% 
        select(starts_with("gamma"))
      
      zeta_draws <- sim_model3_stan_sim3 %>% 
        select(starts_with("zeta"))
      
      f_draws <- sim_model3_stan_sim2 %>% 
        select(starts_with("f"))
      
      
      lam0_vec <- apply(lam0_draws, 2, mean)
      lam1_vec <- apply(lam1_draws, 2, mean)
      lam0_par_est <- matrix(0,
        nrow = length(object_par$f_vec_1),
        ncol = length(object_par$f_vec_1)
      )
      lam1_par_est <- matrix(0,
        nrow = length(object_par$f_vec_1),
        ncol = length(object_par$f_vec_1)
      )
      
      clean_sim_data <- cleanSimulationData(
        raw_data = sim_model3_data,
        cut_off = cut_off,
        N = length(object_par$f_vec_1)
      )
      
      for (i in seq_along(lam0_vec)) {
        row_id <- clean_sim_data$I_fit[i]
        col_id <- clean_sim_data$J_fit[i]
        lam0_par_est[row_id, col_id] <- lam0_vec[i]
        lam1_par_est[row_id, col_id] <- lam1_vec[i]
      }
      
      
      ###
      
      #############
      mmhp_par_est <- list(
        lambda0 = lam0_par_est,
        lambda1 = lam1_par_est,
        eta_1 = mean(sim_model3_stan_sim3$eta_1),
        eta_2 = mean(sim_model3_stan_sim3$eta_2),
        eta_3 = mean(sim_model3_stan_sim3$eta_3),
        beta = mean(sim_model3_stan_sim3$beta),
        f = apply(f_draws, 2, mean)
      )
      
      object_hat <- list(
        lambda0 = mmhp_par_est$lambda0[cur_i, cur_j],
        lambda1 = mmhp_par_est$lambda1[cur_i, cur_j],
        alpha = model3_fn$alpha.fun(
          mmhp_par_est$f[cur_i],
          mmhp_par_est$f[cur_j],
          mmhp_par_est$eta_1,
          mmhp_par_est$eta_2
        ),
        beta = mmhp_par_est$beta,
        q1 = model3_fn$q1.fun(
          mmhp_par_est$f[cur_i],
          mmhp_par_est$f[cur_j],
          mmhp_par_est$eta_3
        ),
        q2 = model3_fn$q0.fun(
          mmhp_par_est$f[cur_i],
          mmhp_par_est$f[cur_j],
          mmhp_par_est$eta_3
        )
      )
      
      ## then need to load in the state estimate here
      load(paste0(here("output", "revisions", "sim_m3"),
        "/", "fit123_state_est_",
        plot.s,
        ".RData"
      ))
      
      state.est.latent.mmhp <- interpolate_state_est_lst[plot.i, plot.j][[1]]
      state.est.latent.mmhp.new <- fixInterpolateState(state.est.latent.mmhp,
        termination = 200
      )
      
      step.fun.est <- stepfun(
        state.est.latent.mmhp$x.hat,
        2 - state.est.latent.mmhp$z.hat
      )
      
      lambda.m3 <- mmhpIntensityNumeric(
        params = object_hat,
        t = temp.t[-1],
        time.vec = time.segment,
        latent.vec = step.fun.est(time.segment)
      )
      
      object_true <- lapply(object_matrix, function(x) x[plot.i, plot.j])
      names(object_true) <- c("lambda0", "lambda1", "alpha", "beta", "q1", "q2")
      
      lambda.true <- mmhpTrueIntensityNumeric(
        params = object_true,
        t = temp.t,
        latent = list(
          x = fixStateTransition(test.mmhp)$x,
          z = fixStateTransition(test.mmhp)$z
        ),
        time.vec = time.segment
      )
      
      print(range(lambda.m1$lambda.t - lambda.true$lambda.t))
      cat("M1 ----- \n")
      print(range(lambda.m2$lambda.t - lambda.true$lambda.t))
      cat("M2 ----- \n")
      print(range(lambda.m3 - lambda.true$lambda.t))
      cat("M3 ----- \n")
      
    }
  }
}
```


# Redo 5a 


```{r process_sims_5a}
sim_data_path <- "../output/revisions/sim_m3/"

n_sim <- 50

num_nodes <- 20

object_par <- list(sim_lambda_1 = 0.2,
                   sim_eta_1 = 1.5,
                   gamma_var = runif(n = num_nodes,
                                     min = 0.01, max = 0.05),
                   zeta_var = runif(n = num_nodes,
                                    min = 0.01, max = 0.05),
                   sim_eta_2 = 0.6,
                   sim_eta_3 = 3,
                   sim_beta = 2,
                   f_vec_1 = seq(from = 0.05, to = 0.95,
                                 length.out = num_nodes))


## Initialize
N_array <- array(0, dim = c(
  n_sim, length(object_par$f_vec_1),
  length(object_par$f_vec_1)
))
Lambda_model3_array <- array(0, dim = c(
  n_sim, length(object_par$f_vec_1),
  length(object_par$f_vec_1)
))
Lambda_model1_array <- array(0, dim = c(
  n_sim, length(object_par$f_vec_1),
  length(object_par$f_vec_1)
))
Lambda_model2_array <- array(0, dim = c(
  n_sim, length(object_par$f_vec_1),
  length(object_par$f_vec_1)
))
Lambda_true_array <- array(0, dim = c(
  n_sim, length(object_par$f_vec_1),
  length(object_par$f_vec_1)
))
PR_model1_array <- array(0, dim = c(
  n_sim, length(object_par$f_vec_1),
  length(object_par$f_vec_1)
))
PR_model2_array <- array(0, dim = c(
  n_sim, length(object_par$f_vec_1),
  length(object_par$f_vec_1)
))
PR_model3_array <- array(0, dim = c(
  n_sim, length(object_par$f_vec_1),
  length(object_par$f_vec_1)
))
PR_true_array <- array(0, dim = c(
  n_sim, length(object_par$f_vec_1),
  length(object_par$f_vec_1)
))
KS_model1_array <- array(0, dim = c(
  n_sim, length(object_par$f_vec_1),
  length(object_par$f_vec_1)
))
KS_model2_array <- array(0, dim = c(
  n_sim, length(object_par$f_vec_1),
  length(object_par$f_vec_1)
))
KS_model3_array <- array(0, dim = c(
  n_sim, length(object_par$f_vec_1),
  length(object_par$f_vec_1)
))
KS_true_array <- array(0, dim = c(
  n_sim, length(object_par$f_vec_1),
  length(object_par$f_vec_1)
))
KS_p_model1_array <- array(0, dim = c(
  n_sim, length(object_par$f_vec_1),
  length(object_par$f_vec_1)
))
KS_p_model2_array <- array(0, dim = c(
  n_sim, length(object_par$f_vec_1),
  length(object_par$f_vec_1)
))
KS_p_model3_array <- array(0, dim = c(
  n_sim, length(object_par$f_vec_1),
  length(object_par$f_vec_1)
))
KS_p_true_array <- array(0, dim = c(
  n_sim, length(object_par$f_vec_1),
  length(object_par$f_vec_1)
))

## Iteration on 50 simulations
for (s in c(1:n_sim)) {
  print(s)
  load(paste0(sim_data_path, "sim_model3_fit123_", s, ".RData"))
  load(paste(sim_data_path, "fit123_state_est_", s, ".RData", sep = ""))
  clean_sim_data <- cleanSimulationData(
    raw_data = sim_model3_data,
    cut_off = cut_off,
    N = length(object_par$f_vec_1)
  )

  N_array[s, , ] <- clean_sim_data$N_count

  ## model 1
  #########
  ### transform from cmdstan here
  f_draws <- sim_model3_stan_sim1 %>% 
  select(starts_with("f"))
  
  ###
  model1_par_est <- list(
    lambda0 = mean(sim_model3_stan_sim1$lambda0),
    eta_1 = mean(sim_model3_stan_sim1$eta_1),
    eta_2 = mean(sim_model3_stan_sim1$eta_2),
    eta_3 = mean(sim_model3_stan_sim1$eta_3),
    beta = mean(sim_model3_stan_sim1$beta),
    f = apply(f_draws, 2, mean)
  )

  for (i in c(1:num_nodes)) {
    for (j in c(1:num_nodes)[-i]) {
      current_t <- sim_model3_data$mmhp_matrix[i, j][[1]]$tau
      m1_object <- list(
        lambda0 = model1_par_est$lambda0,
        alpha = model1_fn$alpha.fun(
          model1_par_est$f[i],
          model1_par_est$f[j],
          model1_par_est$eta_1,
          model1_par_est$eta_2,
          model1_par_est$eta_3
        ),
        beta = model1_par_est$beta
      )
      Lambda_model1_array[s, i, j] <-
        uniHawkesIntegralIntensity(
          object = m1_object,
          events = current_t,
          termination = tail(current_t, 1)
        )
      Lambda_test <- uniHawkesCompensator(
        object = m1_object,
        events = current_t
      )
      KS_model1_array[s, i, j] <- ks.test(Lambda_test, "pexp")$statistic
      KS_p_model1_array[s, i, j] <- ks.test(Lambda_test, "pexp")$p.value
      PR_model1_array[s, i, j] <- uniHawkesPearsonResidual(
        object = m1_object,
        events = current_t,
        termination =
          tail(current_t, 1)
      )
    }
  }

  ## model2
  #############
  ### convert to cmdstan
  gamma_draws <- sim_model3_stan_sim2 %>% 
  select(starts_with("gamma"))
  zeta_draws <- sim_model3_stan_sim2 %>% 
  select(starts_with("zeta"))
  f_draws <- sim_model3_stan_sim2 %>% 
  select(starts_with("f"))
  
  model2_par_est <- list(
    gamma = apply(gamma_draws, 2, mean),
    zeta = apply(zeta_draws, 2, mean),
    eta_1 = mean(sim_model3_stan_sim2$eta_1),
    eta_2 = mean(sim_model3_stan_sim2$eta_2),
    eta_3 = mean(sim_model3_stan_sim2$eta_3),
    beta = mean(sim_model3_stan_sim2$beta),
    f = apply(f_draws, 2, mean)
  )

  for (i in c(1:num_nodes)) {
    for (j in c(1:num_nodes)[-i]) {
      current_t <- sim_model3_data$mmhp_matrix[i, j][[1]]$tau
      m2_object <- list(
        lambda0 = model2_par_est$gamma[i] +
          model2_par_est$zeta[j],
        alpha = model1_fn$alpha.fun(
          model2_par_est$f[i],
          model2_par_est$f[j],
          model2_par_est$eta_1,
          model2_par_est$eta_2,
          model2_par_est$eta_3
        ),
        beta = model2_par_est$beta
      )
      Lambda_model2_array[s, i, j] <-
        uniHawkesIntegralIntensity(
          object = m1_object,
          events = current_t,
          termination = tail(current_t, 1)
        )
      Lambda_test <- uniHawkesCompensator(
        object = m2_object,
        events = current_t
      )
      KS_model2_array[s, i, j] <- ks.test(Lambda_test, "pexp")$statistic
      KS_p_model2_array[s, i, j] <- ks.test(Lambda_test, "pexp")$p.value
      PR_model2_array[s, i, j] <-
        uniHawkesPearsonResidual(
          object = m2_object,
          events = current_t,
          termination = tail(current_t, 1)
        )
    }
  }

  ## Model3 & true model
  ######
  ### cmdstan part
  lam0_draws <- sim_model3_stan_sim3 %>% 
  select(starts_with("lambda0"))
  lam1_draws <- sim_model3_stan_sim3 %>% 
  select(starts_with("lambda1"))
  f_draws <- sim_model3_stan_sim3 %>% 
  select(starts_with("f"))
  
  if(ncol(lam0_draws) != sum(clean_sim_data$N_count >2)) {
    stop("Mismatch between params and event pairs")
  }
  
  lambda_0_est <- apply(lam0_draws, 2, mean)
  lambda_1_est <- apply(lam1_draws, 2, mean)
  ## then put these into a matrix
  lam0_par_est <- matrix(0,
    nrow = length(object_par$f_vec_1),
    ncol = length(object_par$f_vec_1)
  )
  lam1_par_est <- matrix(0,
    nrow = length(object_par$f_vec_1),
    ncol = length(object_par$f_vec_1)
  )
  for (i in seq_along(lambda_0_est)) {
    row_id <- clean_sim_data$I_fit[i]
    col_id <- clean_sim_data$J_fit[i]
    lam0_par_est[row_id, col_id] <- lambda_0_est[i]
    lam1_par_est[row_id, col_id] <- lambda_1_est[i]
  }
  mmhp_par_est <- list(
    lambda0 = lam0_par_est,
    lambda1 = lam1_par_est,
    eta_1 = mean(sim_model3_stan_sim3$eta_1),
    eta_2 = mean(sim_model3_stan_sim3$eta_2),
    eta_3 = mean(sim_model3_stan_sim3$eta_3),
    beta = mean(sim_model3_stan_sim3$beta),
    f = apply(f_draws, 2, mean)
  )
  clean_sim_data <- cleanSimulationData(
    raw_data = sim_model3_data,
    cut_off = cut_off,
    N = length(object_par$f_vec_1)
  )

  for (i in c(1:num_nodes)) {
    for (j in c(1:num_nodes)[-i]) {
      test.mmhp <- sim_model3_data$mmhp_matrix[i, j][[1]]
      temp.t <- test.mmhp$tau
      current.n <- length(temp.t) - 1
      time.segment <- seq(0, tail(temp.t, 1), length.out = 10000)

      object_hat <- list(
        lambda0 = mmhp_par_est$lambda0[i, j],
        lambda1 = mmhp_par_est$lambda1[i, j],
        alpha = model3_fn$alpha.fun(
          mmhp_par_est$f[i],
          mmhp_par_est$f[j],
          mmhp_par_est$eta_1,
          mmhp_par_est$eta_2
        ),
        beta = mmhp_par_est$beta,
        q1 = model3_fn$q1.fun(
          mmhp_par_est$f[i],
          mmhp_par_est$f[j],
          mmhp_par_est$eta_3
        ),
        q2 = model3_fn$q0.fun(
          mmhp_par_est$f[i],
          mmhp_par_est$f[j],
          mmhp_par_est$eta_3
        )
      )

      object_true <- lapply(object_matrix, function(x) x[i, j])
      names(object_true) <- c("lambda0", "lambda1",
                              "alpha", "beta", "q1", "q2")

      ## est Lmabda and [R]
      Lambda.test <- mmhpCompensator(
        params = object_hat,
        t = temp.t,
        pzt = 2 -
          event_state_est_lst[i, j][[1]]$zt_v,
        if.pzt = FALSE
      )
      KS_model3_array[s, i, j] <- ks.test(Lambda.test, "pexp")$statistic
      KS_p_model3_array[s, i, j] <- ks.test(Lambda.test, "pexp")$p.value
      state.est.latent.mmhp <- interpolate_state_est_lst[i, j][[1]]
      step.fun.est <- stepfun(
        state.est.latent.mmhp$x.hat,
        2 - state.est.latent.mmhp$z.hat
      )
      est.intensity <- mmhpIntensityNumeric(
        params = object_hat,
        t = temp.t[-1],
        time.vec = time.segment,
        latent.vec =
          step.fun.est(time.segment)
      )
      est.intensity.events <- mmhpIntensityAtEvents(
        params = object_hat,
        t = temp.t,
        latent_z =
          event_state_est_lst[i, j][[1]]$zt_v
      )
      Lambda_model3_array[s, i, j] <-
        sum(est.intensity) * (time.segment[2] - time.segment[1])
      PR_model3_array[s, i, j] <- sum(1 / sqrt(est.intensity.events)) -
        sum(sqrt(est.intensity)) * (time.segment[2] - time.segment[1])

      ## Under the true model
      Lambda.test.true <- mmhpCompensator(
        params = object_true,
        t = temp.t,
        pzt = 2 -
          test.mmhp$zt[2:length(test.mmhp$zt)],
        if.pzt = FALSE
      )
      KS_true_array[s, i, j] <- ks.test(Lambda.test.true, "pexp")$statistic
      KS_p_true_array[s, i, j] <- ks.test(Lambda.test.true, "pexp")$p.value
      true.intensity <-
        mmhpTrueIntensityNumeric(
          params = object_true,
          t = temp.t,
          latent = list(
            ## these are the truth
            x = fixStateTransition(test.mmhp)$x,
            z = fixStateTransition(test.mmhp)$z
          ),
          time.vec = time.segment
        )
      true.intensity.events <- mmhpIntensityAtEvents(
        params = object_true,
        t = temp.t,
        latent_z = test.mmhp$zt
      )
      Lambda_true_array[s, i, j] <- sum(true.intensity$lambda.t) *
        (time.segment[2] - time.segment[1])
      PR_true_array[s, i, j] <- sum(1 / sqrt(true.intensity.events)) -
        sum(sqrt(true.intensity$lambda.t)) * (time.segment[2] - time.segment[1])
    }
  }
  rm(sim_model3_data)
}

```


```{r old_fig5a}
cols_plot <- col_df %>% filter(method %in% c("C-HP","C-DCHP","C-MMHP",
                                 "True")) %>%
  arrange(factor(method, levels = c("C-HP","C-DCHP","C-MMHP","True"))) %>%
  pull(cols)
#load("../output/sim_model3_fit123_residuals.RData")
par(mfrow=c(5,5),mar=c(0.2,0.2,0.2,0.2),oma=c(2.4,2.4,2.9,0.5))
for(i in c(5:1)){
  for(j in c(5:1)){
    if(i==j){
      plot(1,1,type="n",xlim=c(0,1),ylim=c(0,1),
           bty="n", xlab="",ylab="",xaxt="n",yaxt="n",axes=FALSE)
      if(i==5){
        polygon(c(0,0,0.15,0.15),c(0.72,0.8,0.8,0.72)+0.04, 
                col = cols_plot[1], border = NA)
        polygon(c(0,0,0.15,0.15),c(0.72,0.8,0.8,0.72)+0.04-0.22,
                col = cols_plot[2], border = NA)
        polygon(c(0,0,0.15,0.15),c(0.72,0.8,0.8,0.72)+0.04-0.44,
                col = cols_plot[3], border = NA)
        polygon(c(0,0,0.15,0.15),c(0.72,0.8,0.8,0.72)+0.04-0.66,
                col = cols_plot[4], border = NA)
        text(c(0.43,0.58,0.61,0.4), seq(0.8,0.14,-0.22),
             c("C-HP", "C-DCHP", "C-MMHP", "True"),
             cex=1.7)
      }
    }else{
    # PR <- c((N_array-Lambda_model1_array)[,i,j],(N_array-Lambda_model2_array)[,i,j],
      #         (N_array-Lambda_model3_array)[,i,j],(N_array-Lambda_true_array)[,i,j])
      PR <- c(KS_model1_array[,i,j], KS_model2_array[,i,j],
              KS_model3_array[,i,j], KS_true_array[,i,j])
      ### try pr scores instead
      # PR <- c(PR_model1_array[,i,j],PR_model2_array[,i,j],
      #         PR_model3_array[,i,j],PR_true_array[,i,j])
      Type <- c(rep(1,n_sim), rep(2,n_sim), rep(3,n_sim), rep(4,n_sim))
      boxplot(PR ~ Type,  
              col = cols_plot,
              xlab="", ylab="",xaxt="n",yaxt="n")
      #names = c("C-HP", "C-HP-DC", "C-MMHP", "True")
    }
  }
}
# mtext(text=c(1:5), side=2, line=0.5, outer=TRUE, cex=2, las=2,
#       at=c(0:4)/5+0.1)
# mtext(text=c(5:1), side=1, line=1.5, outer=TRUE, cex=2,
#       at=c(0:4)/5+0.1)
# mtext(text="(a)",side=3,line=0.5,outer=TRUE,cex=2.5,font=2)


```


```{r new-5a}
cols_plot <- col_df %>% 
  filter(method %in% c("C-HP","C-DCHP","C-MMHP", "True")) %>%
  arrange(factor(method, levels = c("C-HP", "C-DCHP", "C-MMHP", "True"))) %>%
  pull(cols)


m1_ks <- tibble(Method = "C-HP",
       ks = as.vector(KS_model1_array[sims, ,]))

m2_ks <- tibble(Method = "C-DCHP",
       ks = as.vector(KS_model2_array[sims, ,]))

m3_ks <- tibble(Method = "C-MMHP",
       ks = as.vector(KS_model3_array[sims, ,]))

true_ks <- tibble(Method = "True",
       ks = as.vector(KS_true_array[sims, ,]))

all_ks <- m1_ks %>% 
  bind_rows(m2_ks) %>% 
  bind_rows(m3_ks) %>% 
  bind_rows(true_ks)

all_ks$Method <- factor(all_ks$Method, levels = c("C-HP",
                                                "C-DCHP",
                                                "C-MMHP",
                                                "True") )

all_ks %>% 
  ggplot(aes(Method, ks)) + 
  geom_boxplot(aes(fill = Method)) +
  scale_fill_manual(values = cols_plot) +
  labs(y = "KS Statistic")



m1_pr <- tibble(Method = "C-HP",
       pr = as.vector(PR_model1_array[sims, ,]))

m2_pr <- tibble(Method = "C-DCHP",
       pr = as.vector(PR_model2_array[sims, ,]))

m3_pr <- tibble(Method = "C-MMHP",
       pr = as.vector(PR_model3_array[sims, ,]))

true_pr <- tibble(Method = "True",
      pr = as.vector(PR_true_array[sims, ,]))

all_pr <- m1_pr %>% 
  bind_rows(m2_pr) %>% 
  bind_rows(m3_pr) %>% 
  bind_rows(true_pr)

all_pr$Method<- factor(all_pr$Method, levels = c("C-HP",
                                                "C-DCHP",
                                                "C-MMHP",
                                                "True") )
all_pr %>% 
  ggplot(aes(Method, pr)) + 
  geom_boxplot(aes(fill = Method)) +
  scale_fill_manual(values = cols_plot) +
  labs(y = "Pearson Residual")
```


```{r ks-p-value}

m1_ks_p <- tibble(Method = "C-HP",
       ks = as.vector(KS_p_model1_array[sims, ,]))

m2_ks_p <- tibble(Method = "C-DCHP",
       ks = as.vector(KS_p_model2_array[sims, ,]))

m3_ks_p <- tibble(Method = "C-MMHP",
       ks = as.vector(KS_p_model3_array[sims, ,]))

true_ks_p <- tibble(Method = "True",
       ks = as.vector(KS_p_true_array[sims, ,]))

all_ks_p <- m1_ks_p %>% 
  bind_rows(m2_ks_p) %>% 
  bind_rows(m3_ks_p) %>% 
  bind_rows(true_ks_p)

all_ks_p$Method <- factor(all_ks_p$Method, levels = c("C-HP",
                                                "C-DCHP",
                                                "C-MMHP",
                                                "True") )

all_ks_p %>% 
  filter(ks != 0) %>% 
  mutate(log_p = -log(ks)) %>% 
  ggplot(aes(log_p)) + 
  geom_histogram(aes(fill = Method)) +
  scale_fill_manual(values = cols_plot) +
  labs(y = "Negative Log KS Statistic P Value") +
  facet_wrap(~Method)


```


```{r take-mean-ks/pr}
m1_ks <- tibble(Method = "C-HP",
       ks = as.vector(apply(KS_model1_array, c(2,3), mean)))

m2_ks <- tibble(Method = "C-DCHP",
       ks = as.vector(apply(KS_model2_array, c(2,3), mean)))

m3_ks <- tibble(Method = "C-MMHP",
       ks = as.vector(apply(KS_model3_array, c(2,3), mean)))

true_ks <- tibble(Method = "True",
                  ks = as.vector(apply(KS_true_array, c(2,3), mean)))

all_ks <- m1_ks %>% 
  bind_rows(m2_ks) %>% 
  bind_rows(m3_ks) %>% 
  bind_rows(true_ks)

all_ks$Method <- factor(all_ks$Method, levels = c("C-HP",
                                                "C-DCHP",
                                                "C-MMHP",
                                                "True") )

all_ks %>% 
  ggplot(aes(Method, ks)) + 
  geom_boxplot(aes(fill = Method)) +
  scale_fill_manual(values = cols_plot) +
  labs(y = "KS Statistic", title = "Average per Node Pair")



####
m1_pr <- tibble(Method = "C-HP",
       pr = as.vector(apply(PR_model1_array, c(2,3), mean)))

m2_pr <- tibble(Method = "C-DCHP",
       pr = as.vector(apply(PR_model2_array, c(2,3), mean)))

m3_pr <- tibble(Method = "C-MMHP",
       pr = as.vector(apply(PR_model3_array, c(2,3), mean)))

true_pr <- tibble(Method = "True",
                  pr = as.vector(apply(PR_true_array, c(2,3), mean)))

all_pr <- m1_pr %>% 
  bind_rows(m2_pr) %>% 
  bind_rows(m3_pr) %>% 
  bind_rows(true_pr)

all_pr$Method<- factor(all_pr$Method, levels = c("C-HP",
                                                "C-DCHP",
                                                "C-MMHP",
                                                "True") )
all_pr %>% 
  ggplot(aes(Method, pr)) + 
  geom_boxplot(aes(fill = Method)) +
  scale_fill_manual(values = cols_plot) +
  labs(y = "Pearson Residual", title = "Average Residual per Node Pair")
```